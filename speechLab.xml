<?xml version="1.0" encoding="UTF-8"?>
<chapter xml:id="SpeechLab">
    <title>Speech and Language Laboratory</title>

    <section xml:id="speechLab_intro">
        <title>Speech and Language laboratory</title>

        <introduction>
            <p>The speech and language research group in SCSE was founded in 2007 by Chng Eng Siong and
            <url href="http://www.colips.org/~eleliha/"><c>Prof Li Haizhou</c></url> (now in CUHK-Shenzen, China). 
            The group is now situated within <url href="https://maps.ntu.edu.sg/#/ntu/"><c>HESL Lab - N4-B2b-05</c></url> in SCSE. We also founded the <url href="https://aisingapore.org/aiproducts/speech-lab/"><c>AISG Speech Lab</c></url> funded by NRF since 2018~current.
            </p>
        </introduction>

        <subsection>
            <title>Research Focus</title>
            <p> Our research interest is primarily speech and language processing, classifications using ML:</p>
            <ol label="1">     
                <li> <c>ASR and LLM</c>
                <ol label="a">     
                    <li>Speech LLM research with AISG SeaLion team <url href="https://sea-lion.ai/"><c>Speech SeaLion</c></url>and StepFun team <url href="https://arxiv.org/abs/2507.16632"><c>Step Audio 2</c></url></li>
                    <li>Tranfer Learning: from large trained LLM model for under-resourced languages (Indonesian-English, Malay-English)</li>
                    <li>Using LLM to improve ASR by generative error correction: see <url href="https://arxiv.org/pdf/2309.15701.pdf"><c>Hyporadise</c></url></li>
                    <li>Robust Large vocabulary continuous speech recognition: joint end-to-end ASR with speech enhancement module, wave2vec2, speaker extraction</li>
                    <li>Speech enhancement: speaker extraction, denoising, feature enhancement, overlapping speech extraction</li>
                   </ol>
                </li>
                <li> <c>Classification</c>
                <ol label="a">     
                    <li>Noisy Audio event and scene classifications, Audio captioning <url href="http://dcase.community/challenge2020/task-automatic-audio-captioning"><c>DCase</c></url></li>
                <li>Speaker identification and speaker diarization: diarization, VAD, and speaker extraction issues, see <url href="https://arxiv.org/abs/2010.11458"><c>Microsoft diarization approach</c></url></li>
                <li>Deep Fake Detection (and generation)<url href="https://paperswithcode.com/task/deepfake-detection"><c>Link</c></url></li>
                </ol>
                </li>

                <li><c>Towards Speech Understanding</c> - some aspects of NLP such as topic detection, name entity recognition, text normalization. See a demo of our ASR for ATC speech with NER highlighting.
                <url href="https://www.youtube.com/watch?v=CFsaeK6vP7k"><c>ATC with NER</c></url>
                </li>
            </ol>


	<p>	Examples of relevant papers to the research area include:
	<url href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46687.pdf"><c>sequence to sequence model</c></url>
	which has been widely studied in <url href="https://arxiv.org/abs/1609.08144"><c>machine translation</c></url>. 
	The problems we are keen on include
	<ul>
		<li>	Code switch end to end and Adaptation -> 
			how to improve the model in certain target environment (speaker, noise, type of dialogues), etc.
		<url href="https://dblp.org/pers/p/Pham:Van_Tung.html"><c>Code-switch End-to-end</c></url></li>

		<li>	Classification-> what type of sound is this? <url href="http://dcase.community/challenge2019/index"><c>Audio Scene and Event Analysis</c></url></li>
		<li>    Speaker id: who spoke it: <url href="http://danielpovey.com/files/2019_interspeech_xvector_refinement.pdf"><c>speaker id</c></url>
				under <url href="https://arxiv.org/pdf/1902.02546.pdf"><c>overlapping condition</c></url> 
				and  <url href="https://ai.googleblog.com/2018/11/accurate-online-speaker-diarization.html"><c>when (Diarization).</c></url></li>

		<li> 	Speech Enhancement -  <url href="https://www.researchgate.net/publication/340643534_SpEx_Multi-Scale_Time_Domain_Speaker_Extraction_Network"><c>speaker extraction</c></url> and 
				<url href="https://link.springer.com/article/10.1186/s13634-015-0300-4"><c>derevberation</c></url>.</li>

	</ul>
	</p>


        </subsection>            

        <subsection>
            <title>Demos</title>
            <p>Some of our previous works:</p>
            <ol label='1'>
               <li> <p>Youtube recordings: Our code-switch speech recognition in action:
                    <ol label="a">
                    <li><url href="https://www.youtube.com/watch?v=qfLTJkvYZYc"><c>Recognizing  English/Mandarin code-switch speech using our LVCSR system</c></url> (2018 June).</li>
                    <li><url href="https://www.youtube.com/watch?v=wuQQ3fLu5yE"><c>Comparing our system against  Google, Siri</c></url> (2018 Sep).</li>
                    </ol>
                </p></li>

                <li><p>Source separation - Separating Hillary Clinton and Trump voice from Youtube recording, from Chenglin's  
                    <url href="https://www.dropbox.com/s/jdzrwz1ojobad35/2018_Chenglin_DemoTrumpvsHillary.pptx?dl=0"><c>Demo slide</c></url> (Oct 2018)</p></li>

            
                <li><p>Speech indexing using our MAGOR system (Code-switch English/Mandarin and Malay system)
                <image source = './images/magor_picture.jpg' /></p> </li>

                <li><p>See a demo of our ASR for ATC speech with NER highlighting.
                    <url href="https://www.youtube.com/watch?v=CFsaeK6vP7k"><c>ATC with NER</c></url>
                    <image source = './images/ATC_Demo.jpg' />
                
            </p></li>

            </ol>
        </subsection>            

        <subsection>
            <title>Our recent demos using our speech engine</title>
            <p>2020 FYPs demo:</p>
            <ol label='1'>

                <li><p>Deploying Speech Recognition System using high availability and scalability kubernetes cluster <url href="https://www.youtube.com/watch?v=le79VEOjeuQ"><c>Youtube</c></url></p></li>

                 <li><p>Chatbot framework using Dialog flow and various Q and A modules (2020 Demo)
                    <url href="https://www.youtube.com/watch?v=upFpCp4LDgo"><c>Youtube</c></url>
                    and a live demo<url href="https://chatbot.speechlab.sg/"><c>Demo</c></url>
                    <image source = './images/russell_chatbotPic2020.jpg' /> </p> </li>

            </ol>
        </subsection>            


        <subsection>
        		<title>Some of our recent works in git</title>
        		<ol label = '1'>
        				<li><p>PhD Student Hou Nana's work in NTU (2018~2021), single channel speech enhancement, <url href="https://github.com/nanahou/Awesome-Speech-Enhancement"><c>github</c></url></p></li>
        				<li><p>PhD Student Xu Chenglin's work in NTU (2015~2020), single channel speech separation/extration,<url href="https://github.com/xuchenglin28/"><c>github</c></url></p></li>
        				<li><p>Intern GeMeng's work (intern from Tianjin 2020~2021), tutorial speech separation, <url href="https://github.com/gemengtju/Tutorial_Separation"><c>github</c></url></p></li>
        				<li><p>Intern Shangeths work (intern from BITS) (2020 Aug- 2021 June), Accent, Age, Height classification<url href="https://www.dropbox.com/s/z834va4hvfngzo8/Shangeth%E2%80%99s%20Work%20at%20Speech%20Lab%2C%20NTU%20Singapore.pdf?dl=0"><c>Pdf link</c></url></p></li>
        				<li><p>MSAI student Samuel Samsudin (2020~2021), emotion detection,
                            <url href="https://github.com/samsudinng/speech_emo_recognition.git"><c>github depository</c></url>, 
                        <url href="https://www.kaggle.com/samuelsamsudinng/iemocap-emotion-speech-database"><c>kaggle iEmoCap</c></url></p></li>
                        <li><p>Language Identification by EEE's PhD student Liu Hexin (2021) <url href="https://github.com/Lhx94As/Awesome-Spoken-Language-Identification"><c>github link</c></url></p></li>                       
                        <li><p>Intern Shashank Shirol's work (2020 Jan-June), using GAN to create noisy speech, <url href="https://github.com/shashankshirol/GeneratingNoisySpeechData"><c>github depository</c></url></p></li>
        		</ol>
        </subsection>

    </section>
            

    <section xml:id="my_collaborator">
           <title>Collaborators</title>
            <p><ol label="1">
            <li><url href="https://www.linkedin.com/in/kong-aik-lee-3b49a868"><c>A/Prof Lee KongAik</c></url>, HK Poly Uni (Speaker Anonymisation, SV, DeepFake (2023~)) </li>
            <li><url href="https://drwuz.com/"><c>A/Prof Wu Zhizheng</c></url>, CUHK (TTS, (2023~))</li>
            <li><url href="https://faculty.dukekunshan.edu.cn/faculty_profiles/ming-li"><c>A/Prof Li Ming</c></url>, Duke-Kunshan (Deep Fake, (2023~))</li>
            <li><url href="https://sds.cuhk.edu.cn/en/teacher/498"><c>Prof Li Haizhou</c></url>, CUHK and AISG Speech Lab (since 2008~)</li>
            <li><url href="https://scholar.google.com.sg/citations?user=V-ISRXwAAAAJ"><c>Prof Zhong Xionghu</c></url>, Hunan University, China. Microphone Array DOA and diarization. (2019~)</li>
            <li><url href="https://www.linkedin.com/in/bin-ma-b278a44b/"><c>Dr Ma Bin</c></url>, Alibaba. Robust End-to-End Code switch ASR (2018~)</li>
            <li><url href="https://scholar.google.com/citations?user=gCxEFxIAAAAJ"><c>Prof Huang Hao</c></url>, Xinjiang University. PhD students exchange -  Code switch ASR and classification (2018~)</li>
            <li><url href="http://www.nwpu-aslp.org/lxie/"><c>Prof Xie Lei</c></url>, Northwestern Polytechnic, Xian, China. PhD students exchange - ASR (2015~)</li>
            <li><url href="http://cic.tju.edu.cn/faculty/wanglongbiao/experiences.html"><c>Prof Wang Longbiao</c></url>, Tianjin University, China. PhD students exchange - Emotion recognition (2016~)</li>
            <li><url href="https://www.researchgate.net/profile/Linhui-Sun-3"><c>A/Prof Sun Linhui</c></url>, (Speech Enhancement (2022~)) </li>
            </ol>        </p>

    <subsection xml:id="Past_collaborator">
           <title>Past Collaborators</title>
            <p><ol label="1">
            <li><url href="https://gr.xjtu.edu.cn/web/xiwei"><c>Prof XI Wei</c></url>, Xian JiaoTong University, China. CSC PhD students exchange - self-supervised learning </li>
            <li><url href="https://www.linkedin.com/in/rafaelbanchs/"><c>Dr Raphael Banchs</c></url>, ChatBot.</li>
            <li><url href="https://chl.ece.gatech.edu/"><c>Prof Lee Chin Hui</c></url>, Robust ASR (~2008-2015) </li>
            <li><url href="https://www.uni-bremen.de/en/csl/team/staff/prof-dr-ing-tanja-schultz/"><c>Prof Tanja Schultz</c> (~2008-2013)</url>, Code-switch ASR</li>
            </ol></p>
    </subsection>


    </section>

    <section xml:id="my_Staff">
            <title>Staff</title>
            <p><ol label="1">
            <li><url href="https://www.linkedin.com/in/wei-rao-49382080/"><c>Dr Rao Wei</c></url>,senior research fellow (LLM) (joned April 2025~)</li>


            <li><url href="https://www.linkedin.com/in/hexin-liu-2a7a91212/?originalSubdomain=sg"><c>Dr Liu Hexin</c></url>,research fellow (LLM) (joned Oct 2023~)</li>
            <li><url href="https://www.hieuthi.com/"><c>Dr Luong Hieu Thi</c></url>,research fellow (Deepfake) (joined Jan 2024~Dec 2025)</li>

            <li><url href="https://www.linkedin.com/in/lyvt1/"><c>Ly Vu Thi</c></url>,Full-stack and chatBot</li>

            
            <li><url href="https://www.linkedin.com/in/tanmay-surana-118a79192/"><c>Tanmay Surana</c></url>, <c>NLP and Depression classification</c> (Jan 2024~)</li>
            <li><url href="https://sg.linkedin.com/in/lim-zhi-hao-025546115"><c>Lim Zhi Hao</c></url> Speaker verification and DNN</li>
            <li><url href="https://www.linkedin.com/in/kyaw-zin-tun-170b52122"><c>Kyaw Zin Tun (AISG-NTU)</c></url>, full-stack development</li>
            <li><url href="https://www.linkedin.com/in/yizhou-peng-18425b202/?originalSubdomain=cn"><c>Peng Yizhou (AISG-NUS)</c></url>, speech research, in NUS AISG lab (Jan 2023~)</li>
            <li><url href="https://www.linkedin.com/in/adnan-azmat-496000153/?originalSubdomain=sg"><c>Azmat Adnan</c></url>,Research Associate (joned April 2025~)</li>
            <li><url href="https://www.linkedin.com/in/nurshahidahj/"><c>Nur Shahidah Binte Jamaludin</c></url>, corpus development and linguistic support, (Sep 2021~)</li>
            <li><url href="https://www.linkedin.com/in/changsong-liu/"><c>Liu Changsong</c></url>,Project Officer (joned Aug 2024~)</li>

            </ol></p>

    <subsection xml:id="Past_Staff">
    <title>Past Staff</title>
    <p><ol label="1">

            <li><url href="https://sg.linkedin.com/in/ngaho"><c>Ho Thi Nga</c></url>, sentence unit detection and full-stack, backend. (May 2013~Jul 2024)</li>


            <li><url href="https://www.linkedin.com/in/nabilah-ismail-6b3aa0164"><c>Nabilah Ismail</c></url>, Corpus Development (joined Oct 2020~Oct2023</li>

            <li><url href="https://gemengtju.github.io/"><c>Dr Ge Meng</c></url>,research fellow NUS AISG (Speech recognition) (Oct 2019~Apr 2020, then 2023~2024 for Prof Morning project)</li>


            <li><url href="https://www.linkedin.com/in/RajendraPrasadSirigina9b691859/"><c>Dr Rajendra Prasad Sirigina</c></url>, Research Fellow, Time series, 2019 Feb-> 2021 June </li>

            <li><url href="https://www.linkedin.com/in/maduo-843771197/"><c>Ma Duo (AISG-NUS) </c></url>, LVCSR and classification, 2019-2021</li>

            <li><url href="https://www.linkedin.com/in/tungpv85/"><c>Dr Pham Van Tung</c></url>, Research Fellow, Speech recognition, end-to-end, keyword spotting, Jan 2012-2021 May</li>

            <li><url href="https://www.linkedin.com/in/haihua-xu-42757419"><c>Dr Xu Haihua</c></url>, Principal Research Fellow, Robust LVCSR, keyword spotting, Feb 2012-2021 March</li>
            <li><url href="https://www.linkedin.com/in/duc-mai-trung-1410/"><c>Mai Trung Duc</c></url>, full-stack and mobile app development, Mar 2019-Dec2021</li>

            <li><url href="https://www.linkedin.com/in/xuchenglin28"><c>Xu Chenglin</c></url>, PhD (2020), 
            Single Channel Multi-talker Speech Separation with Deep Learning</li>
            <li><url href="https://www.linkedin.com/in/zengzhiping/"><c>Zeng Zhiping</c></url>, LVCSR, March 2018- April 2020</li>
            <li><url href="https://www.linkedin.com/in/danyuan-ho-4a7312173/"><c>Ho Danyuan</c></url>, corpus development and linguistic, May 2018-March 2020</li>
            <li><url href="https://www.linkedin.com/in/xhtian/"><c>Tian XiaoHai</c></url>, TTS and voice morphing, part-time PhD and Staff, 2013-2018. Now in NUS.</li>
            <li><url href="https://www.linkedin.com/in/wei-rao-49382080"><c>Rao Wei</c></url>, Speaker verification, 2015-2018, Now in NUS.</li>
            <li><url href="https://www.linkedin.com/in/xiong-xiao-0a6a9b29/"><c>XiaoXiong</c></url>, PhD Student 2004-2008, Staff 2008-2017, Now in Microsoft, Redmond - since Apr 2017</li>
            <li><url href="https://www.linkedin.com/in/benjamin-bigot-ab175291/"><c>Benjamin Bigot</c></url>, 2014-2016 - LVCSR for RR</li>
            <li><url href="https://orcid.org/0000-0001-5880-7956"><c>Huang Guangpu</c></url>, 2012-2015 - Articulatory Phonetics Features  </li>
            <li><url href="https://www.linkedin.com/in/dau-cheng-lyu-48794916/"><c>Lyu Daucheng</c></url>,  2009-2013 - Code switch LVCSR</li>
            <li><url href="https://www.linkedin.com/in/shengkui-zhao-%EF%BC%88%E8%B5%B5%E8%83%9C%E5%A5%8E%EF%BC%89-74983b22/"><c>Zhao Shengkui</c></url>,2009-2010 - Microphone array and beamforming.</li>

        </ol></p>
    </subsection>


    </section>




    <section xml:id="my_Students">
            <title>Current PhD and Graduate Students</title>
            <p><ol label="1">

            <li><url href="https://ziyang.tech/"><c>Ma Ziyang</c></url>, Advancing LLM research (PhD reg Aug 2022, Supervisor: Chng Eng Siong, Shanghai Jiao Tong: Chen Xie)</li> 

            <li><url href="linkedin.com/in/yizhou-peng-18425b202?originalSubdomain=sg"><c>Peng Yizhou</c></url>, Versatile Large Speech Language Modeling for Duplex Dialogue Systems (PhD reg Jan 2025, Supervisor: Chng Eng Siong)</li> 

            <li><url href="https://www.linkedin.com/in/yi-wen-chao-407277295/"><c>Chao Yi-Wen</c></url>, Paralinguistics-enhanced LLM for Spoken Dialogue System  (PhD reg Aug 2024, Supervisor: Chng Eng Siong, AStar: Lu Yanfeng)</li> 



            <li><url href="https://www.linkedin.com/in/yeoyueheng"><c>Yeo Yue Heng</c></url>, LLM for speech recognition (PhD reg Jan 2024, Supervisor: Chng Eng Siong, AStar Co-Sup:Tran Huy Dat), AStar Scholar</li>


            <li><url href="https://www.linkedin.com/in/davisl44622"><c>Li Haoyang</c></url>, Neural Text to Speech (PhD reg Aug 2023)</li>

            <li><url href="https://www.linkedin.com/in/ductuantruong/"><c>Tuan Truong Duc</c></url>, Robust Speaker verification and Deep Fake Detection under noisy and short duration scenario (reg Jan 2023, PhD)</li>
            <li><url href="https://www.linkedin.com/in/fabian-ritter-gutierrez-9ab4317a/"><c>Fabian Ritter Gutierrez</c></url>,End2End ASR for Language Learning (PhD, reg Aug 2022, AStar scholar) (co-supervised with AStar: Nancy Chen. QE (2024):  <url href="https://github.com/FabianRitter/NTU_QE_PRESENTATION/tree/main"><c> Github of Thesis and Video</c></url></li>
            <li><url href="https://www.linkedin.com/in/paniquex/"><c>Nikita Kuzmin</c></url>, Disentaglement for Speaker verification and privacy (PhD, reg Aug 2022, AStar scholar) (co-supervised with AStar: Lee Kong Aik. <url href="https://github.com/paniquex/PHD_QE_NTU"><c>QE: 2025 </c></url> </li>


 
            
            </ol></p>     


         <subsection xml:id="my_co_sup_Students">
            <title>Current Co-Sup: PhD Students</title>
            <p><ol label="1">
            <li><url href="https://www.linkedin.com/in/ashutosh-anshul-b12508148"><c>Ashutosh Anshul</c></url>, Multi-modal Deep Fake classification and detection (reg Jan 2024, Supervisor: Deepu Rajan, Co-Sup:Chng Eng Siong)</li>

            <li><url href="https://www.linkedin.com/in/the-shreyas-gopal/"><c>Shreyas Gopas</c></url>, Speech Recognition using LLM for under-resourced languages (reg Jan 2024, Supervisor: Quek Hiok Chai, Co-Sup:Chng Eng Siong)</li>
            
            </ol></p>    
            </subsection> 

     <subsection xml:id="my_MSAI_Students">
         <title>Current MEng and Masters Program Students</title>
         <p><ol label="1">

            <li><url href=""><c>Wang Yuxi</c></url>, Voice Conversion  Audio Security: Classification of Audio for Deepfake and Audio Watermarking Presence (MEng reg Aug 2025, Supervisor: Chng Eng Siong)</li> 

            <li><url href="https://www.linkedin.com/in/songting-liu-b0098b220/"><c>Liu Songting</c></url>, Voice Conversion  (MEng reg Aug 2024, Supervisor: Chng Eng Siong)</li> 

                <li><url href="https://www.linkedin.com/in/%E4%BE%9D%E8%B1%AA-%E5%90%B4-0b5523325/"><c>Wu Yihao</c></url>, Robust diarization for large scale meeting scenario  (MEng reg Aug 2024, Supervisor: Chng Eng Siong)</li> 


                <li><url href=""><c>Hu Guoqiang</c></url>, LLM for Audio editing tasks  (MEng reg Aug 2025, Supervisor: Chng Eng Siong)</li> 
            
             </ol>
            </p></subsection>


            <subsection xml:id="my_collaborator_Students_China">
            <title>Collaborating graduate Student (China)</title>
            <p>
            Every year, we will host graduate students from China. We have hosted students from China Scholarship Council (program), 
            Peking University, Xinjiang University, Hunan University, Tianjin University and Northwestern University. The visits have been very rewarding, and many publications have come out of these visits.
            We hope to see more such outstanding students, so do apply! </p>


            <p><ol label="1">

            <li><url href="https://arxiv.org/abs/2311.17382"><c>Yang Yuhang</c></url> (2023 June~, PhD student (Hunan University), China), LLM ASR</li>

            <li><url href="https://www.linkedin.com/in/xiangyu-zhang-a0735b194/"><c>Zhang Xiangyu</c></url> (2023 June~, PhD student (UNSW, Australia), Depression classification</li>

            </ol>
            </p></subsection>





    <subsection xml:id="Past_PhD_Students">
    <title>Past PhD Students</title>
    <image source = './images/recentPhDGrad.jpg' /> 



    <p><ol label="1" > 

            
            <li><url href="https://www.linkedin.com/in/aaron-kwok-b1163b1b4/"><c>Kwok Chin Yuen</c></url>, Efficient Adaptation of Speech
Foundation Models for Low-Resource Tasks (reg Aug 2021, MEng, converted to PhD program, Aug 2022)
            <url href="https://www.dropbox.com/scl/fi/32z7zo6c69n4f48pdle9u/aaron_thesis_Sep_18_2025.pdf?rlkey=xbth2wwpczgq4ehgu7kox6zxh?dl=0"><c>PhD Thesis (submitted Sep 2025)</c></url>
        </li>



            <li><url href="https://yuchen005.github.io/"><c>Hu Yuchen 胡宇晨 </c></url>, Advances in End-to-End Robust
Automatic Speech Recognition (reg Aug 2021, MEng, converted to PhD program, Aug 2022, Thesis submitted: June 2025). 
            <url href="https://www.dropbox.com/scl/fi/1pexppbvzxzvbflnndku5/phd_thesis_hyc_revised_Sep2025.pdf?rlkey=6u9v0jf4smxbnhucndlmly3d1?dl=0"><c>PhD Thesis (final version: Sep 2025)</c></url>
        <url href="https://www.dropbox.com/scl/fi/4max4uevisy2agmz29or0/2023_HuYuchenQE_QE_presentation.pptx?rlkey=bbrrdv0h042wi4b23gah2r3ct"><c>QE Slides (2023)</c></url>
        </li>


<li><url href="https://www.linkedin.com/in/yip-jia-qi/"><c>Yip Jia Qi</c></url>, From Time-domain to Generative
Speech Separation (reg Aug 2021, Alibaba scholar PhD) <url href="https://www.dropbox.com/scl/fi/40c7mlxcfz8qblo081xs0/2025_YipJiaQi_final.pdf?rlkey=458iqptqohyano3rpomfm1f6p?st=6kr67ham?dl=0"><c>(Thesis (final): June 2025) </c></url> </li>


<li><url href="https://sites.google.com/view/hqzou/"><c>Zou HeQing</c></url>, Multimodal Machine Learning (reg Jan 2021, submitted June 2025, PhD) (Sup:Deepu Rajan, Co-Sup: Chng Eng Siong)</li>


<li><url href="https://www.linkedin.com/in/chen-chen-4bb7231b8/"><c>Chen Chen</c></url>, Advancing Speech-to-Text Adaptation for
Large Speech Models (PhD reg Jan 2021) (defended: June2025) 
<url href="https://scholar.google.com.hk/citations?user=uUmSp1QAAAAJ?hl=zh-CN"><c>Google Scholar</c></url>, <url href="https://www.dropbox.com/scl/fi/v79bwgr475qbdhc4ddtb9/2025_ChenChen_final.pdf?rlkey=907s46bm6avomfaxi7paedsn1?dl=0"><c>(Thesis final: June 2025)</c></url></li>
        

           <li><url href="https://www.linkedin.com/in/dianwen-ng-34691a129/"><c>Ng Dian Wen</c></url>, Optimizing Speech Representation
Learning for Enhanced Noise Robustness in Downstream Applications (PhD reg Jan 2021, graduated 2025 May, Alibaba scholar PhD) 
<url href="https://www.dropbox.com/scl/fi/5aped99ygawmsqxy7yr0l/2025_dianwen_final.pdf?rlkey=k6vr2hrzjh974d1tt49th8hld?st=wgmg7bdu?dl=0"><c>(Thesis :May 2025)</c></url></li>


        <li><url href="https://www.linkedin.com/in/rae-jia-xin-koh-9b10b3105/"><c>Rae Koh Jia Xin</c></url>, Singapore English (reg Aug 2019, PhD) (graduated 2025) (Sup: Tan Ying Ying (HSS), Co-Sup: Chng Eng Siong)</li>

        <li><url href="https://www.linkedin.com/in/andrew-koh-5464a5118/"><c>Andrew Koh Jin Jie</c></url>, Sequence to Sequence Machine Learning (reg Aug 2019, PhD, graduated 2023)</li>

        <li><url href="https://www.linkedin.com/in/yingzhuzhaophd/"><c>Zhao Yingzhu</c></url>, End-to-End speech recognition (reg Jan 2019, PhD, graduated May 2023). <url href="https://youtu.be/6vCzAem8Hbo"><c>Oral Defence rehearsal</c></url>
    <url href="https://www.dropbox.com/s/x9hcwk383htwlvl/Yingzhu_oral_SlidesApr2023.pptx?dl=0"><c>PhD Slides</c></url>
    <url href="https://www.dropbox.com/s/1yf2ajg86777bzq/2023_April_thesis_ZhaoYingzhu.pdf?dl=0"><c>PhD report</c></url>
    <url href="https://www.dropbox.com/s/26as7mwlafg0akg/ZhaoYingZhu_PhDThesis_Apr2023Latex.zip?dl=0"><c>PhD latex folder</c></url>
</li>
      

        <li><url href="https://www.linkedin.com/in/nana-hou-592a80127/"><c>Hou Nana</c></url>, Robust LVCSR for air traffic control speech 
        (reg Jan 2017, PhD, submitted Jan 2022)</li>

	    <li><url href="https://www.linkedin.com/in/xuchenglin28"><c>Xu Chenglin</c></url>,
 	    <url href="https://www.dropbox.com/s/as78r4txv0z27kc/ChenglinPhDDefenceSlidesAug2020.pptx?dl=0"><c>PhD Slides</c></url>
		<url href="https://www.dropbox.com/s/zn6ad5j3lose4r6/ChenglinPhDThesis18July2020.pdf?dl=0"><c>PhD Thesis</c> (2020) Single Channel Multi-talker Speech Separation with Deep Learning</url></li>

 	    <li><url href="https://www.linkedin.com/in/paul-yaozhu-chan-9408777a/"><c>Paul Chan</c></url>, Synthesis of the human singing voice (2020)</li>

        <li><url href="https://www.linkedin.com/in/khassanov/"><c>Khassan Yerbolat</c></url>, <url href=
        "https://www.dropbox.com/s/1z4d6y2fd5crdwk/2020_Khassan_Slides.pptx?dl=0"><c>PhD Slides</c> </url>,
        <url href="https://www.youtube.com/watch?v=1Dm16krGgv0"><c>Online Presentation</c></url>(April 2020)
        and final <url href="https://www.dropbox.com/s/nc6hijq2l6q18ip/Khassan_FinalAmended_Thesis_May2020.pdf?dl=0"><c>PhD thesis.</c></url>,
        (2020) Language Model Domain Adaptation for Automatic Speech Recognition Systems.</li>


        <li><url href="https://www.linkedin.com/in/tungpv85/"><c>Pham Van Tung</c></url>, <url href="https://www.dropbox.com/s/76wrdu426xr4x3z/2019_PhamVanTung_Thesis_amended.pdf?dl=0"><c>PhD Thesis</c> </url>(2019) Robust Spoken Term Detection using partial search and re-scoring hypothesized detections techniques. Now in NTU.</li>

        <li><url href="https://www.linkedin.com/in/xhtian/"><c>Tian Xiaohai</c></url>, <url href="https://www.dropbox.com/s/pli1uh2i9dr3n0r/2019_Xiaohai_Tian_revised.pdf?dl=0"><c>PhD Thesis</c> </url>(2019) Voice Conversion with Parallel/Non-Parallel Data and Synthetic Speech Detection. Now in NUS.</li>
        
        <li><url href="https://www.linkedin.com/in/tze-yuang-chong-4b9b2a61/"><c>Chong Tze Yuang</c></url>, <url href="https://www.dropbox.com/s/9ur3bon1whthsk8/2018_June_ChongTzeYuangPhDThesis.pdf?dl=0"><c>PhD Thesis</c></url>, <url href="https://www.dropbox.com/s/m8y59n6nv0kqjdu/2018_June_ChongTzeYuang_Presentation.pptx?dl=0"><c>Slides</c></url>,
        <url href="https://www.dropbox.com/s/kjfap8a4e1zfnkr/2018_June_ChongTzeYuangPhDThesis_organization.docx?dl=0"><c>Thesis organization</c></url>,
        (2018) Exploiting Long Context Using Joint  Distance and Occurrence Informationfor Language Modeling.</li>

        <li><url href="https://www.linkedin.com/in/ha-nguyen-4101517a/"><c>Nguyen Duc Hoang Ha</c></url>, <url href="https://www.dropbox.com/s/a0gvjb73rqrmb1f/2017_NguyenDucHoangHa_PhDThesis.pdf?dl=0"><c>PhD Thesis</c> </url>(2017) <url href="https://www.dropbox.com/s/pmsluvihe41lk3d/2017_NguyenDucHoangHa_PresentSlide.pdf?dl=0"><c>Slides</c></url>
        Feature based robust techniques for speech recognition.</li>

        <li><url href="https://www.linkedin.com/in/trung-hieu-nguyen-a99569b8/"><c>Nguyen Trung Hieu</c></url>, <url href="https://www.dropbox.com/s/siggnj3dvmu3xq0/2014_NguyenTrungHieu_PhDThesis.pdf?dl=0"><c>PhD Thesis</c> </url>(2015). Speaker Diarization in Meeting room domain. Now at Alibaba.</li>

        <li><url href="https://www.linkedin.com/in/van-hai-do-7a252850/"><c>Do Van Hai</c></url>, <url href="https://www.dropbox.com/s/0v9npacoacghqwf/2015_DoVanHai_PhDThesis.pdf?dl=0"><c>PhD Thesis</c> </url>(2015). Acoustic modelling of speech under limited training data condition. Now in Vietnam Telecoms.</li>

        <li><url href="https://www.linkedin.com/in/zhizhengwu/"><c>Wu Zhizheng</c></url>, <url href="https://www.dropbox.com/s/m6u9ccmuvkbo0av/2015_WuZZ_PhDThesis.pdf?dl=0"><c>PhD Thesis</c> </url>(2015). Spectral Mapping for Voice Conversion.</li>

        <li><url href="https://www.linkedin.com/in/jonathan-dennis-9ab85186/"><c>Jonathan Dennis</c></url>, <url href="https://www.dropbox.com/s/zpxrbvlhto7199y/2014_JohnDennis_PhDThesis2014.pdf?dl=0"><c>PhD Thesis</c> 
        </url>(2014). <url href="https://www.dropbox.com/s/72md2vuw2jebjmy/2014_JonDennis_PhD_oral_defence_slides.pptx?dl=0"><c>Slides</c> </url>,  Sound Event Recognition in Unstructured Environments using Spectrogram Image Processing.</li>

        <li><url href="https://www.linkedin.com/in/lei-wang-44190967/"><c>Wang Lei</c></url>, (2013). Audio Pattern Discovery and retrieval.</li>

        <li><url href="https://www.linkedin.com/in/rong-tong-3028924a/"><c>Tong Rong</c></url>, <url href="https://www.dropbox.com/s/gcqmbqaq9vd52si/2012_TongRong_PhDThesis.pdf?dl=0"><c>PhD Thesis</c> </url>(2012). Towards high performance phonotactic features for spoken language recognition. Now at Alibaba.</li>

        <li><url href="https://www.linkedin.com/in/omiddehzangi/"><c>Omid Dehzanghi</c></url>, (2012). Discriminative Learning for speech recognition, U of Michigan</li>

        <li><url href="https://www.linkedin.com/in/xiong-xiao-0a6a9b29/"><c>Xiao Xiong</c></url>, <url href="https://www.dropbox.com/s/ywqbhkz0vfnh06s/2009_XiaoXiong_PhDThesis.pdf?dl=0"><c>PhD Thesis (2009)</c> 
        </url>. PhD Thesis: Robust speech features and acoustic models for speech recognition. <url href="https://www.dropbox.com/s/7muljjnvlqn5f7r/2006_XiaoXiong_PhD_QE.pdf?dl=0"><c>QE (2006)</c> </url>,Speech Enhancement with Applications in speech recognition,  now in Microsoft, US  since Apr 2017</li>

        <li xml:id="countGraduatedPhD"><url href="https://www.linkedin.com/in/wangjinjun/"><c>Wang Jinjun</c></url>, PhD (2008), Content based sports video analysis and composition. Now in Xian Jiaotong. </li>
    </ol></p>
    </subsection>


    <subsection xml:id="Past_MEng_Students">
    <title>Past MEng Students</title>
    <p><ol label="1">

<li><url href="https://www.linkedin.com/in/yunyi-ni-3a6885325/?original_referer=https%3A%2F%2Fwww%2Egoogle%2Ecom%2F?originalSubdomain=sg"><c>Ni Yunyi</c></url>, VoiceForge: A Text-Driven Character Voice Generation System for Narrative Content Creation (MSAI reg Aug 2024, Supervisor: Chng Eng Siong)</li> 
            <li><url href="https://www.linkedin.com/in/skandml/?originalSubdomain=sg"><c>Thirunavukarasu Suresh Sathya Krishnan</c></url>, Advancing Dialogue Systems: Synthetic
Dialogue Generation and Code-Switching in LLMs (MSAI reg Aug 2024, Supervisor: Chng Eng Siong)</li> 

        <li><url href="https://www.linkedin.com/in/adnan-azmat-496000153/?originalSubdomain=sg"><c>Azmat Adnan</c></url>,(MSAI Thesis, 2024) Robust Diarization</li>
        <li><url href="https://www.linkedin.com/in/tanmay-surana-118a79192/"><c>Tanmay Surana</c></url>, <c>Deep Learning-based Text Augmentation for Named Entity Recognition</c> (reg Aug 2021, MEng, completed Oct 2023)</li>

        <li><url href="https://www.linkedin.com/in/chaiyasait/"><c>Prachaseree Chaiyasait</c></url>, Adaptation of Language Models via Text Augmentation (reg Aug 2021, MEng, submitted Jul 2023, completed Oct 2023)</li>

        <li><url href="https://www.linkedin.com/in/kyaw-zin-tun-170b52122"><c>Kyaw Zin Tun</c></url>, Name entity recognition for chatbot applcications(MEng, started Aug 2020, submitted thesis Aug 2022)</li>

        <li><url href="https://www.linkedin.com/in/fuzhao-xue-6410561a6/"><c>Xue Fuzhao</c></url>, Information extraction from text (MEng 2020)</li>
        <li><url href="https://sg.linkedin.com/in/lim-zhi-hao-025546115"><c>Lim Zhi Hao</c></url>, (MEng 2020), Anti-Spoofing Techniques for Robust
        Speaker Verification<url href="https://www.dropbox.com/s/tjhprq3dvj79hjm/2020_LimZhiHao_Robust_Speaker_Verification.pdf?dl=0"><c>Thesis (2020)</c></url></li>
        <li><url href="https://www.linkedin.com/in/ngaho/"><c>Ho Thi Nga</c></url>, (MEng 2019), Sentence unit detection for automatic speech transcripts using lexical information</li>
        <li><url href="https://www.linkedin.com/in/su-jun-leow-52755085/"><c>Leow Sujun</c></url>, (MEng 2018), Image Processing Technique for Speech Signal Processing</li>
        <li><url href="https://www.linkedin.com/in/hy-nguyen-quy-61292739/"><c>Nguyen Quy Hy</c></url>, (MEng 2017), Voice conversion using DNN</li>
        <li><url href="https://www.linkedin.com/in/steven-du-1662511b/"><c>Steven Du</c></url>, (MEng 2015),  Robust Front End for Speaker Verification</li>
        <li><url href="https://www.linkedin.com/in/terence-ng-70411320/"><c>Terrence Ng Wen Zheng</c></url>, 
        <url href="https://www.dropbox.com/s/2staf3jboruaozr/2014_MENG_TerrenceNgWenZheng.pdf?dl=0"><c>Thesis</c></url>,(MEng 2014), Sound Event recognition in home environment</li>
        <li><url href="https://www.linkedin.com/in/wenda-chen-6261732a/"><c>Chen Wenda</c></url>, (MEng 2014),Computer Assisted Language Learning</li>
        <li><url href="https://www.linkedin.com/in/pckben/"><c>Ben Pham Chau Khoa</c></url>,
            <url href="https://www.dropbox.com/s/tfvf6sx3wpb9eeb/2012_MEng_BenPhamChauKhoa.pdf?dl=0"><c>Thesis</c></url>,(MEng 2012), Robust VAD</li>
        <li xml:id="countGraduatedMEng"> Eugene Koh, (MEng 2009), Speaker Diarizaton</li>
    </ol></p>
    </subsection>

    <subsection xml:id="Past_MSAI_Students">
    <title>Past MSAI Students and Others (CSC) collaboration students</title>
    <p><ol label="1">


            <li><c>Chen Weiguang</c> (2022 June~,2023 PhD student (Hunan University), Diarization using multi-channel approaches</li>

           <li><url href="https://scholar.google.co.uk/citations?user=KjcXd6cAAAAJ"><c>Yao Jixun</c></url> (2023 Oct~ Oct 2024, AISG NUS visitor), PhD student (Northwestern Poly, China), Speech Enhancement and TTS</li>

               <li><url href="https://scholar.google.com/citations?user=GEVwy4sAAAAJ"><c>Le Yuquan</c></url> (2023 Oct~ Oct 2024, CSC visitor), PhD student (Hunan University, China), LLM for Legal</li>

               <li><c>Luo Juan</c> (2023 Oct~ Oct 2024, CSC visitor), PhD student (Hunan University, China), Audio event detection and classification</li>

               <li><url href="https://arxiv.org/abs/2305.10761"><c>Zhang Zizheng</c></url> (2023 June~ Jun 2024, AISG remote), Masters student (Peking University, China), Speech Separation, <url href="https://github.com/TzuchengChang/NASS"><c>github</c></url></li>
               
               <li><url href="https://openreview.net/profile?id=~Haorui_Zheng1"><c>Zheng Haorui</c></url> (2024 June~ , AISG remote), Masters student (Peking University, China), Speaker Diarization with Speech Separation</li>
               

                <li><url href="https://github.com/fluide1022"><c>Bo Han</c></url> (2023 Oct ~Oct 2024, CSC visitor), PhD student Zhejiang Uni, China), Deep Fake TTS audio generation</li>



            <li><url href="https://www.linkedin.com/in/yanru-chen-2b38b8221/"><c>Chen Yanru</c></url> (2024 Jan~), Masters Data Science, Classification of Depression Syndrome by Deep Learning</li>

            <li><url href="https://www.linkedin.com/in/xiaokaiqin/"><c>Qin Xiaokai</c></url> (2023 Aug~), MSAI student, Deepfake audio generation using voice conversion</li>


            <li><url href="https://in.linkedin.com/in/adnan-azmat-496000153"><c>Azmat Adnan</c></url> (Reg 2023 Aug, completed Aug 2024), MSAI student, DNN Approaches for noisy speech diarization </li>

            <li><c>Zhuo Ning</c> (Reg 2023 Aug, completed Aug 2024), Masters Cybersecurity student, Deep Fake Corpus developmenet and detection </li>

                <li><c>Jiang Yufei</c> (2022 Aug~ 2023 Aug), MSAI (NTU), Adopting Neural Translation Model in Data Generation for Inverse Text Normalization</li>
                <li><c>Liu Jiaxing</c> (2021 Oct ~2023 Oct, CSC visitor, PhD student Tianjin University, China), Multi-modal emotion recognition</li>
                <li><c>Cheng Qi</c> (2021 Oct ~2022 Oct, CSC visitor, PhD student Harbin Engineering Uni, China), Graph Neural Network for Lattice rescoring</li>

                 <li><url href="https://www.linkedin.com/in/samuel-samsudin-ng/"><c>Samuel Samsudin Ng</c></url>, (MSAI 2020-S1), Speech emotion recognition with AlexNet and Fully convolutional network,
                <url href="https://www.dropbox.com/s/3ullgc88cfihj2e/2020_MSAI_Report_SamuelSamsudinNg.pdf?dl=0"><c>Sam's MSAI Thesis</c></url>,
                <url href="https://github.com/samsudinng/speech_emo_recognition.git"><c>github depository</c></url>, 
                <url href="https://www.kaggle.com/samuelsamsudinng/iemocap-emotion-speech-database"><c>kaggle iEmoCap</c></url>
                </li>
                <li><url href="https://www.linkedin.com/in/andy-cheung-a0847572/"><c>Cheung Chin Ka</c></url>, (MSAI 2020-S1), Acoustic Scene Classication with cutting edge hyperparameter tuning tool,
                <url href="https://www.dropbox.com/s/0bpudw98ra4f80k/2020_msai-cheung-chin-ka-master-project-report.pdf?dl=0"><c>Andy's MSAI Thesis</c></url> </li>
                <li><url href="https://www.linkedin.com/in/bozhong-sampson-liu/"><c>Liu Bozhong</c></url>, (MSAI 2020-S2), Wakeup keyword detection for far-field microphone array using end to end framework</li>
        </ol></p></subsection>
   

            <subsection xml:id="PastStudents">
            <title>Past MSAI Students and Other collaboration students</title>
            <p><ol label="1">
                <li><c>Zhao Yang</c> (2021 Oct ~2023 Oct, CSC visitor, PhD student Xian JiaoTong Uni, China), Semi/Self supervised representation for speech recognition</li>
                <li><c>Peng Yizhou</c> (2020 June ~2022 June, Masters student Xinjiang, China), ASR development (Kaldi and End2End)</li>
                <li><c>Yang Yuhang</c> (2021 June~2023 June, Masters student Xinjiang, China), WeNet ASR, End2End ASR</li>
                <li><c>Guo Yachao</c> (2021 June~2023 June, Masters student Xinjiang, China), End2End Hotword LM Adaptation</li>
            </ol></p></subsection>
        </section>

    <section xml:id="Past_Interns">
    <title>Internship in Speech Lab@SCSE, NTU</title>


    <introduction>
        <p>We have a tradition of hosting senior undergraduate students (final year) and graduate students (Masters and PhD) in our lab.</p>

        <p>Typically we only host students who can work with us for 6 months or more in 2 sessions.
            Session 1: Jan-June, Session 2: Jul->Dec each year.
            Since covid (it had been remote). 
            Currently we only host students who are doing this as part of their course sanctioned by 
            their school and its graded *so its not a personal arrangement*.
        </p>

       <p> To apply, you should be writing to us at least 1/2 year before the start of the attachment.
        Kindly send me an email with a detailed cv. 
        As we receive huge number of applicants, only shortlisted students will receive a response.
        </p>

        <p>
        We have two tracks,
        one for research and the other for development. For research, we expect students to have work with pyTorch, tensorflow, etc.
        For development, we expect experiene with google summer of code, full stack experience.
        During this internship, you will be actively working with our speech-team researchers on tasks such as implementing and 
        realising state-of-the-art ML/DL techniques and deploying them for various tasks listed below:
        </p>

        <p>
        <alert>Our current Research projects are:</alert></p>
        <p><ol label="1">
            <li>LMM for summarization and Inverse Text Normalization.</li>
            <li> Classification from Audio: Speaker profiling (age, height, weight, accent, emotion) classification, Audio Event classification (DCASE),
             Speaker diarization and overlapping speech detection</li>
             <li> Speech Enhancement and Audio processing:  Enhancing noisy speech to clean DNN approaches, Deep Fake Speech: Modifying audio eavefiles to target environment/speaker/ noise using GAN</li>
         </ol></p>



        <p><alert>Our current Development projects are:</alert></p>
        <p><ol label="1">
            <li>Terraform and cloud deployment of speech engine with scaling, auto-update, security and dashboard.</li>
            <li>MAGOR - search and indexing speech, video and audio</li>
            <li>Async speech recording and recognition Interface - recording and async update of speech recognised with update on name entity</li>
            <li>Transcriptor - GUI for correction of erroneous recognised text</li>
        </ol></p>

        <p> Upon completion of the project, we expect a formal project report +    code repository, and if possible submit the work for publication.</p>
        <p> Pls find attached a writeup by Shashank (2021 intern) onboarding help file, have a look.
            <url href="https://www.dropbox.com/s/fq34mfqtmuvy42a/SpeechLab_Onboarding_Shshank_2021.pdf?dl=0"><c>Onboarding writeup by Shashank</c></url></p>
    


    </introduction>


    <p><alert> Current and Past Interns: </alert></p>

    <p>   The list is incomplete, we began to the tradition of taking pictures with the students from India about 2017,  there were many others. 
    The pictures here include CSC students, undergraduate students, and details included inside.  
    </p>

    <p><ol label="1">
            <li><url href="https://www.dropbox.com/scl/fi/et19yyf5ij5za37vw7syi/Visiting-Student_Intern-2025_CSC.docx?rlkey=oer1ny14pdkz4bh9v1196plkn?e=1?dl=0"><c>2025 group of students</c></url></li>
            <li><url href="https://www.dropbox.com/scl/fi/isftidn65ha7fhaqrisqm/2024_2025_Interns.pdf?rlkey=uoeg0eh6doyb2sno53rmxapce?e=1?st=mv05imeq?dl=0"><c>2024 and 2025 June~Dec(fully remote)</c></url></li>
            <li><url href="https://www.dropbox.com/scl/fi/h8q31r9gw2ck3d9l3a87l/2023_June_Dec_Interns.pdf?rlkey=vlyi0kkfg9mf7mo41c514l6u9"><c>2023 June~Dec(fully remote)</c></url></li>
            <li><url href="https://www.dropbox.com/scl/fi/ix2zecra23egczjk83x43/Interns-Jan-June2023.pdf?rlkey=v1fddv3g0n5etibyqsbskndtc"><c>Some pictures of our group meetings with Interns from 2023(fully remote)</c></url></li>
            <li><url href="https://www.dropbox.com/scl/fi/re9mcme80i63cnmefoqnl/Interns-2022.pdf?rlkey=tidhkiguwqmgjj6sm6wnaquxt"><c>Some pictures of our group meetings with Interns from 2022(fully remote)</c></url></li>
            <li><url href="https://www.dropbox.com/s/qpbyp5yb8mxujcg/pic_2021.docx?dl=0"><c>Some pictures of our group meetings with Interns from 2021(fully remote)</c></url></li>
            <li><url href="https://www.dropbox.com/s/6jncuc9srnekg3o/MICL_Interns_AugDec2020.pdf?dl=0"><c>Interns from 2020 (July-Dec) (fully remote)</c></url></li>
            <li><url href="https://www.dropbox.com/s/qj1c3lytdy8b7mz/MICL_Interns_feb2020.pdf?dl=0"><c>Interns from 2020 (Jan-May) (our last group before we could not have students in Singapore)</c></url></li>
            <li><url href="https://www.dropbox.com/s/eu0ewshlvcpu9xp/MICL_Interns_Nov%202019_Grp1.pdf?dl=0"><c>Interns from 2019 (Nov, Grp1)</c></url></li>
            <li><url href="https://www.dropbox.com/s/cbeqnrd5vu7nl9s/MICL_Interns_Nov%202019_Grp2.pdf?dl=0"><c>Interns from 2019 (Nov, Grp2)</c></url></li>
            <li><url href="https://www.dropbox.com/s/e7t42elpkkepxla/MICL_Interns_July2019.pdf?dl=0"><c>Interns from 2019 (Jul)</c></url></li>
            <li><url href="https://www.dropbox.com/s/hhvxdkrsy36umxp/MICL_interns_Apr2019.pdf?dl=0"><c>Interns from 2019 (Apr)</c></url></li>
            <li><url href="https://www.dropbox.com/s/5kvr37n34m5dgso/InternsGroupPhotoOct2018a.pdf?dl=0"><c>Interns from 2018 (Oct)</c></url></li>
            <li><url href="https://www.dropbox.com/s/p96jev90lw1n5iq/InternsGroupPhotoJuly2018.pdf?dl=0"><c>Interns from 2018 (Jul)</c></url></li>
            <li><url href="https://www.dropbox.com/s/yur445nl12lwvlk/InternsGroupPhotoMay2018.pdf?dl=0"><c>Interns from 2018 (May)</c></url></li>
            <li><url href="https://www.dropbox.com/s/u16qn9f4lu7hqai/InternsGroupPhotoJan2018.pdf?dl=0"><c>Interns from 2018 (Jan)</c></url></li>
            <li><url href="https://www.dropbox.com/s/hup912rma6p9loc/MMLInternsNTU2017.pdf?dl=0"><c>Interns from 2017 (Jul)</c></url></li>
            <li><url href="http://www.linkedin.com/in/gangeshwark"><c>Gangeshwar Krishnamurthy,2017 (Jan-Apr)</c></url></li>
            <li><url href="https://www.linkedin.com/in/shengheng-gao-2779043a/"><c>Gao Shengheng,2016 (Mar-Jun)</c></url></li>
            </ol></p>
    </section>
    
</chapter>
