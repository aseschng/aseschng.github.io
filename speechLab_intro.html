<!DOCTYPE html>
<!--**************************************-->
<!--*    Generated from PreTeXt source   *-->
<!--*    on 2025-03-18T18:31:03+08:00    *-->
<!--*                                    *-->
<!--*      https://pretextbook.org       *-->
<!--*                                    *-->
<!--**************************************-->
<html lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Speech and Language laboratory</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width,  initial-scale=1.0, user-scalable=0, minimum-scale=1.0, maximum-scale=1.0">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [['\\(','\\)']]
    },
    asciimath2jax: {
        ignoreClass: ".*",
        processClass: "has_am"
    },
    jax: ["input/AsciiMath"],
    extensions: ["asciimath2jax.js"],
    TeX: {
        extensions: ["extpfeil.js", "autobold.js", "https://pretextbook.org/js/lib/mathjaxknowl.js", "AMScd.js", ],
        // scrolling to fragment identifiers is controlled by other Javascript
        positionToHash: false,
        equationNumbers: { autoNumber: "none", useLabelIds: true, },
        TagSide: "right",
        TagIndent: ".8em",
    },
    // HTML-CSS output Jax to be dropped for MathJax 3.0
    "HTML-CSS": {
        scale: 88,
        mtextFontInherit: true,
    },
    CommonHTML: {
        scale: 88,
        mtextFontInherit: true,
    },
});
</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_CHTML-full"></script><script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.13/pretext.js"></script><script src="https://pretextbook.org/js/0.13/pretext_add_on.js"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.31/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.31/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.31/banner_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.31/toc_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.31/knowls_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.31/style_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.31/colors_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.31/setcolors.css" rel="stylesheet" type="text/css">
<!-- 2019-10-12: Temporary - CSS file for experiments with styling --><link href="developer.css" rel="stylesheet" type="text/css">
</head>
<body class="mathbook-book has-toc has-sidebar-left">
<a class="assistive" href="#content">Skip to main content</a><div class="hidden-content" style="display:none">\(
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\)</div>
<header id="masthead" class="smallbuttons"><div class="banner"><div class="container">
<a id="logo-link" href="https://www.ntu.edu.sg/home/aseschng/default.html" target="_blank"><img src="images/ntu_img.png" alt="Logo image"></a><div class="title-container">
<h1 class="heading"><a href="default.html"><span class="title">Chng Eng Siong</span></a></h1>
<p class="byline"></p>
</div>
</div></div>
<nav id="primary-navbar" class="navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active" aria-label="Show or hide table of contents sidebar">Contents</button><div class="tree-nav toolbar toolbar-divisor-3"><span class="threebuttons"><a id="previousbutton" class="previous-button toolbar-item button" href="SpeechLab.html" title="Previous">Prev</a><a id="upbutton" class="up-button button toolbar-item" href="SpeechLab.html" title="Up">Up</a><a id="nextbutton" class="next-button button toolbar-item" href="my_collaborator.html" title="Next">Next</a></span></div>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="SpeechLab.html" title="Previous">Prev</a><a class="up-button button toolbar-item" href="SpeechLab.html" title="Up">Up</a><a class="next-button button toolbar-item" href="my_collaborator.html" title="Next">Next</a>
</div>
</div></nav></header><div class="page">
<div id="sidebar-left" class="sidebar" role="navigation"><div class="sidebar-content">
<nav id="toc"><ul>
<li class="link"><a href="intro1.html" data-scroll="intro1"><span class="codenumber">1</span> <span class="title">Introduction</span></a></li>
<li class="link">
<a href="SpeechLab.html" data-scroll="SpeechLab"><span class="codenumber">2</span> <span class="title">Speech and Language Laboratory</span></a><ul>
<li><a href="speechLab_intro.html" data-scroll="speechLab_intro" class="active">Speech and Language laboratory</a></li>
<li><a href="my_collaborator.html" data-scroll="my_collaborator">Collaborators</a></li>
<li><a href="my_Staff.html" data-scroll="my_Staff">Staff</a></li>
<li><a href="my_Students.html" data-scroll="my_Students">Current PhD and Graduate Students</a></li>
<li><a href="Past_Interns.html" data-scroll="Past_Interns">Internship in Speech Lab@SCSE, NTU</a></li>
</ul>
</li>
<li class="link">
<a href="Teaching.html" data-scroll="Teaching"><span class="codenumber">3</span> <span class="title">Teaching Activities</span></a><ul>
<li><a href="GraduateStudents.html" data-scroll="GraduateStudents">Graduate Students</a></li>
<li><a href="UndergraduateStudents.html" data-scroll="UndergraduateStudents">UnderGraduate Students</a></li>
<li><a href="section-8.html" data-scroll="section-8">Courses Taught</a></li>
<li><a href="section-9.html" data-scroll="section-9">Some relevant E-Learning Videos</a></li>
</ul>
</li>
<li class="link">
<a href="FundlingList.html" data-scroll="FundlingList"><span class="codenumber">4</span> <span class="title">Fundings</span></a><ul>
<li><a href="Current_Fundings.html" data-scroll="Current_Fundings">Current Fundings</a></li>
<li><a href="Past_Fundings.html" data-scroll="Past_Fundings">Past Fundings</a></li>
</ul>
</li>
</ul></nav><div class="extras"><nav><a class="mathbook-link" href="https://pretextbook.org">Authored in PreTeXt</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a></nav></div>
</div></div>
<main class="main"><div id="content" class="pretext-content"><section class="section" id="speechLab_intro"><h2 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber">2.1</span> <span class="title">Speech and Language laboratory</span>
</h2>
<a href="speechLab_intro.html" class="permalink">Â¶</a><section class="introduction" id="introduction-2"><p id="p-14">The speech and language research group in SCSE was founded in 2007 by Chng Eng Siong and <a class="external" href="http://www.colips.org/~eleliha/" target="_blank"><code class="code-inline tex2jax_ignore">Prof Li Haizhou</code></a> (now in CUHK-Shenzen, China). The group is now situated within <a class="external" href="https://maps.ntu.edu.sg/#/ntu/" target="_blank"><code class="code-inline tex2jax_ignore">HESL Lab - N4-B2b-05</code></a> in SCSE. We also founded the <a class="external" href="https://makerspace.aisingapore.org/do-ai/speech-lab/" target="_blank"><code class="code-inline tex2jax_ignore">AISG Speech Lab</code></a> funded by NRF since 2018~current.</p></section><section class="subsection" id="subsection-1"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">2.1.1</span> <span class="title">Research Focus</span>
</h3>
<p id="p-15">Our research interest is primarily speech and language processing, classifications using ML:</p>
<ol class="decimal">
<li id="li-7">
<code class="code-inline tex2jax_ignore">ASR and LLM</code><ol class="lower-alpha">
<li id="li-8">Using LLM to improve ASR by generative error correction: see <a class="external" href="https://arxiv.org/pdf/2309.15701.pdf" target="_blank"><code class="code-inline tex2jax_ignore">Hyporadise</code></a>
</li>
<li id="li-9">Code-switch multi-lingual speech recognition: see <a class="external" href="https://arxiv.org/abs/1811.09021" target="_blank"><code class="code-inline tex2jax_ignore">Audio to Byte</code></a>
</li>
<li id="li-10">Robust Large vocabulary continuous speech recognition: joint end-to-end ASR with speech enhancement module, wave2vec2, speaker extraction</li>
<li id="li-11">Speech enhancement: speaker extraction, denoising, feature enhancement, overlapping speech extraction</li>
<li id="li-12">Faster decoding with end-to-end and real time android based decoders</li>
<li id="li-13">Tranfer Learning: from large trained acoustic model (16KHz) to  8KHz models via transfer learning</li>
</ol>
</li>
<li id="li-14">
<code class="code-inline tex2jax_ignore">Classification</code><ol class="lower-alpha">
<li id="li-15">Noisy Audio event and scene classifications, Audio captioning <a class="external" href="http://dcase.community/challenge2020/task-automatic-audio-captioning" target="_blank"><code class="code-inline tex2jax_ignore">DCase</code></a>
</li>
<li id="li-16">Speaker identification and speaker diarization: diarization, VAD, and speaker extraction issues, see <a class="external" href="https://arxiv.org/abs/2010.11458" target="_blank"><code class="code-inline tex2jax_ignore">Microsoft diarization approach</code></a>
</li>
<li id="li-17">Deep Fake Detection (and generation)<a class="external" href="https://paperswithcode.com/task/deepfake-detection" target="_blank"><code class="code-inline tex2jax_ignore">Link</code></a>
</li>
</ol>
</li>
<li id="li-18">
<code class="code-inline tex2jax_ignore">Towards Speech Understanding</code> - some aspects of NLP such as topic detection, name entity recognition, text normalization. See a demo of our ASR for ATC speech with NER highlighting. <a class="external" href="https://www.youtube.com/watch?v=CFsaeK6vP7k" target="_blank"><code class="code-inline tex2jax_ignore">ATC with NER</code></a>
</li>
</ol>
<p id="p-16">Examples of relevant papers to the research area include: <a class="external" href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46687.pdf" target="_blank"><code class="code-inline tex2jax_ignore">sequence to sequence model</code></a> which has been widely studied in <a class="external" href="https://arxiv.org/abs/1609.08144" target="_blank"><code class="code-inline tex2jax_ignore">machine translation</code></a>. The problems we are keen on include</p>
<ul class="disc">
<li id="li-19">Code switch end to end and Adaptation -&gt; how to improve the model in certain target environment (speaker, noise, type of dialogues), etc. <a class="external" href="https://dblp.org/pers/p/Pham:Van_Tung.html" target="_blank"><code class="code-inline tex2jax_ignore">Code-switch End-to-end</code></a>
</li>
<li id="li-20">Classification-&gt; what type of sound is this? <a class="external" href="http://dcase.community/challenge2019/index" target="_blank"><code class="code-inline tex2jax_ignore">Audio Scene and Event Analysis</code></a>
</li>
<li id="li-21">Speaker id: who spoke it: <a class="external" href="http://danielpovey.com/files/2019_interspeech_xvector_refinement.pdf" target="_blank"><code class="code-inline tex2jax_ignore">speaker id</code></a> under <a class="external" href="https://arxiv.org/pdf/1902.02546.pdf" target="_blank"><code class="code-inline tex2jax_ignore">overlapping condition</code></a> and  <a class="external" href="https://ai.googleblog.com/2018/11/accurate-online-speaker-diarization.html" target="_blank"><code class="code-inline tex2jax_ignore">when (Diarization).</code></a>
</li>
<li id="li-22">Speech Enhancement -  <a class="external" href="https://www.researchgate.net/publication/340643534_SpEx_Multi-Scale_Time_Domain_Speaker_Extraction_Network" target="_blank"><code class="code-inline tex2jax_ignore">speaker extraction</code></a> and <a class="external" href="https://link.springer.com/article/10.1186/s13634-015-0300-4" target="_blank"><code class="code-inline tex2jax_ignore">derevberation</code></a>.</li>
</ul></section><section class="subsection" id="subsection-2"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">2.1.2</span> <span class="title">Demos</span>
</h3>
<p id="p-17">Some of our previous works:</p>
<ol class="decimal">
<li id="li-23">
<p id="p-18">Youtube recordings: Our code-switch speech recognition in action:</p>
<ol class="lower-alpha">
<li id="li-24">
<a class="external" href="https://www.youtube.com/watch?v=qfLTJkvYZYc" target="_blank"><code class="code-inline tex2jax_ignore">Recognizing  English/Mandarin code-switch speech using our LVCSR system</code></a> (2018 June).</li>
<li id="li-25">
<a class="external" href="https://www.youtube.com/watch?v=wuQQ3fLu5yE" target="_blank"><code class="code-inline tex2jax_ignore">Comparing our system against  Google, Siri</code></a> (2018 Sep).</li>
</ol>
</li>
<li id="li-26"><p id="p-19">Source separation - Separating Hillary Clinton and Trump voice from Youtube recording, from Chenglin's <a class="external" href="https://www.dropbox.com/s/jdzrwz1ojobad35/2018_Chenglin_DemoTrumpvsHillary.pptx?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">Demo slide</code></a> (Oct 2018)</p></li>
<li id="li-27"><p id="p-20">Speech indexing using our MAGOR system (Code-switch English/Mandarin and Malay system) <div class="image-box" style="width: 100%; margin-left: 0%; margin-right: 0%;"><img src="./images/magor_picture.jpg" style="width: 100%; height: auto;" alt=""></div></p></li>
<li id="li-28"><p id="p-21">See a demo of our ASR for ATC speech with NER highlighting. <a class="external" href="https://www.youtube.com/watch?v=CFsaeK6vP7k" target="_blank"><code class="code-inline tex2jax_ignore">ATC with NER</code></a> <div class="image-box" style="width: 100%; margin-left: 0%; margin-right: 0%;"><img src="./images/ATC_Demo.jpg" style="width: 100%; height: auto;" alt=""></div></p></li>
</ol></section><section class="subsection" id="subsection-3"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">2.1.3</span> <span class="title">Our recent demos using our speech engine</span>
</h3>
<p id="p-22">2020 FYPs demo:</p>
<ol class="decimal">
<li id="li-29"><p id="p-23">Deploying Speech Recognition System using high availability and scalability kubernetes cluster <a class="external" href="https://www.youtube.com/watch?v=le79VEOjeuQ" target="_blank"><code class="code-inline tex2jax_ignore">Youtube</code></a></p></li>
<li id="li-30"><p id="p-24">Chatbot framework using Dialog flow and various Q and A modules (2020 Demo) <a class="external" href="https://www.youtube.com/watch?v=upFpCp4LDgo" target="_blank"><code class="code-inline tex2jax_ignore">Youtube</code></a> and a live demo<a class="external" href="https://chatbot.speechlab.sg/" target="_blank"><code class="code-inline tex2jax_ignore">Demo</code></a> <div class="image-box" style="width: 100%; margin-left: 0%; margin-right: 0%;"><img src="./images/russell_chatbotPic2020.jpg" style="width: 100%; height: auto;" alt=""></div></p></li>
</ol></section><section class="subsection" id="subsection-4"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">2.1.4</span> <span class="title">Some of our recent works in git</span>
</h3>
<ol class="decimal">
<li id="li-31"><p id="p-25">PhD Student Hou Nana's work in NTU (2018~2021), single channel speech enhancement, <a class="external" href="https://github.com/nanahou/Awesome-Speech-Enhancement" target="_blank"><code class="code-inline tex2jax_ignore">github</code></a></p></li>
<li id="li-32"><p id="p-26">PhD Student Xu Chenglin's work in NTU (2015~2020), single channel speech separation/extration,<a class="external" href="https://github.com/xuchenglin28/" target="_blank"><code class="code-inline tex2jax_ignore">github</code></a></p></li>
<li id="li-33"><p id="p-27">Intern GeMeng's work (intern from Tianjin 2020~2021), tutorial speech separation, <a class="external" href="https://github.com/gemengtju/Tutorial_Separation" target="_blank"><code class="code-inline tex2jax_ignore">github</code></a></p></li>
<li id="li-34"><p id="p-28">Intern Shangeths work (intern from BITS) (2020 Aug- 2021 June), Accent, Age, Height classification<a class="external" href="https://www.dropbox.com/s/z834va4hvfngzo8/Shangeth%E2%80%99s%20Work%20at%20Speech%20Lab%2C%20NTU%20Singapore.pdf?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">Pdf link</code></a></p></li>
<li id="li-35"><p id="p-29">MSAI student Samuel Samsudin (2020~2021), emotion detection, <a class="external" href="https://github.com/samsudinng/speech_emo_recognition.git" target="_blank"><code class="code-inline tex2jax_ignore">github depository</code></a>, <a class="external" href="https://www.kaggle.com/samuelsamsudinng/iemocap-emotion-speech-database" target="_blank"><code class="code-inline tex2jax_ignore">kaggle iEmoCap</code></a></p></li>
<li id="li-36"><p id="p-30">Language Identification by EEE's PhD student Liu Hexin (2021) <a class="external" href="https://github.com/Lhx94As/Awesome-Spoken-Language-Identification" target="_blank"><code class="code-inline tex2jax_ignore">github link</code></a></p></li>
<li id="li-37"><p id="p-31">Intern Shashank Shirol's work (2020 Jan-June), using GAN to create noisy speech, <a class="external" href="https://github.com/shashankshirol/GeneratingNoisySpeechData" target="_blank"><code class="code-inline tex2jax_ignore">github depository</code></a></p></li>
</ol></section></section></div></main>
</div>
</body>
</html>
