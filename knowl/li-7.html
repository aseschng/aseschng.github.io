<!DOCTYPE html>
<html lang="en-US">
<!--**************************************-->
<!--*    Generated from PreTeXt source   *-->
<!--*    on 2025-01-21T11:23:43+08:00    *-->
<!--*                                    *-->
<!--*      https://pretextbook.org       *-->
<!--*                                    *-->
<!--**************************************-->
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="robots" content="noindex, nofollow">
</head>
<body>
<article class="li"><h6 class="heading">
<span class="type">Item</span><span class="space"> </span><span class="codenumber">1</span><span class="period">.</span>
</h6>
<code class="code-inline tex2jax_ignore">ASR and LLM</code><ol class="lower-alpha">
<li>Using LLM to improve ASR by generative error correction: see <a class="external" href="https://arxiv.org/pdf/2309.15701.pdf" target="_blank"><code class="code-inline tex2jax_ignore">Hyporadise</code></a>
</li>
<li>Code-switch multi-lingual speech recognition: see <a class="external" href="https://arxiv.org/abs/1811.09021" target="_blank"><code class="code-inline tex2jax_ignore">Audio to Byte</code></a>
</li>
<li>Robust Large vocabulary continuous speech recognition: joint end-to-end ASR with speech enhancement module, wave2vec2, speaker extraction</li>
<li>Speech enhancement: speaker extraction, denoising, feature enhancement, overlapping speech extraction</li>
<li>Faster decoding with end-to-end and real time android based decoders</li>
<li>Tranfer Learning: from large trained acoustic model (16KHz) to  8KHz models via transfer learning</li>
</ol></article><span class="incontext"><a href="speechLab_intro.html#li-7">in-context</a></span>
</body>
</html>
