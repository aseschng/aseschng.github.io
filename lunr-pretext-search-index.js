var ptx_lunr_search_style = "textbook";
var ptx_lunr_docs = [
{
  "id": "intro1",
  "level": "1",
  "url": "intro1.html",
  "type": "Chapter",
  "number": "1",
  "title": "Introduction",
  "body": " Introduction    I joined NTU in 2003, and am currently an Associate Professor in the School of Computer Science and Engineering , Singapore.    My main research interest is in speech and lanaguge processing, and I am the PI of AISG Speech Lab with interest to develop robust code-switch ASR using LLM capabilities. Other research interests include: NLP and machine learning. To date, I have been Principal Investigator of several research grants awarded by Alibaba, Webank, AISG, NTU-Rolls Royce, Mindef, MOE and AStar with a total funding amount of over S$13 million under the Speech and Language Laboratory at SCSE, supervised (PhD Students)= and supervised (MEng Students)= . Publications include 2 edited books and over ~150 journal\/conference papers.  Working experience prior to joining NTU: Knowles Electronics (2001-2002), Lernout and Hauspie (1999-2000,Belgium), Institute of Infocomm Research (1996-1999,I2R, Singapore), and RIKEN (1996,Japan).  Education: received both BEng (Hons) and PhD from Edinburgh University> , U.K. in 1991 and 1996 respectively. PhD research thesis was supervised by Bernard Mulgrew , Peter Grant and Chen Sheng   Served as the publication chair for 5 international conferences (Human Agent Interaction 2016, INTERSPEECH 2014, APSIPA-2010, APSIPA-2011, ISCSLP-2006), and have been an associate editor for IEICE (special issue 2012), a reviewer for Speech Communications, Eupsico, IEEE Trans Man,System and Cybernectics Part B, Journal of Signal Processing System, ACM Multimedia Systems, IEEE Trans Neural Network, IEEE Trans CAS-II, and Signal Processing.  I am a PhD supervisor and PI for 4 AIR projects in Alibaba ( 达摩院) NTU-Joint Research institute (speech research) Speech research  Was the recipient of the Tan Chin Tuan fellowship (2007) to visit Tsinghua University, the JSPS travel grant award (2008) to visit Tokyo Institute of Technology, and the Merlion Singapore-France research collaboration award in 2009.  What others say about me: LinkedIn , Google Scholar , Semantic Scholar  Research.com   Lastly, some pictures of the team and various bikes rode across the years. Some more recent pictures (2019,2020) pictures from ICASSP 2019, and team 2020 . 2022 (ICASSP) pictures from ICASSP 2022 and HCM .  How to find me?    My office: Blk N4, 02c-96, Nanyang Avenue. School of Computer Science and Engineering. Nanyang Technological University,Singapore 639798  Map: SCSE Block N4 MapLink  Q: How to get to NTU?  Q: Nearest carpark to Blk N4 is Car Park F  Email: aseschng at ntu dot edu dot sg,  Tel : +65-6790-6200, Fax: +65-6792-6559     Visited by ClusterMap  Last Updated: 26 April 2021  This web page was produced using PreTeXt   "
},
{
  "id": "speechLab_intro",
  "level": "1",
  "url": "speechLab_intro.html",
  "type": "Section",
  "number": "2.1",
  "title": "Speech and Language laboratory",
  "body": " Speech and Language laboratory   The speech and language research group in SCSE was founded in 2007 by Chng Eng Siong and Prof Li Haizhou (now in CUHK-Shenzen, China). The group is now situated within HESL Lab - N4-B2b-05 in SCSE. We also founded the AISG Speech Lab funded by NRF since 2018~current.    Research Focus  Our research interest is primarily speech and language processing, classifications using ML:    ASR and LLM   Using LLM to improve ASR by generative error correction: see Hyporadise  Code-switch multi-lingual speech recognition: see Audio to Byte  Robust Large vocabulary continuous speech recognition: joint end-to-end ASR with speech enhancement module, wave2vec2, speaker extraction  Speech enhancement: speaker extraction, denoising, feature enhancement, overlapping speech extraction  Faster decoding with end-to-end and real time android based decoders  Tranfer Learning: from large trained acoustic model (16KHz) to 8KHz models via transfer learning     Classification   Noisy Audio event and scene classifications, Audio captioning DCase  Speaker identification and speaker diarization: diarization, VAD, and speaker extraction issues, see Microsoft diarization approach  Deep Fake Detection (and generation) Link    Towards Speech Understanding - some aspects of NLP such as topic detection, name entity recognition, text normalization. See a demo of our ASR for ATC speech with NER highlighting. ATC with NER    Examples of relevant papers to the research area include: sequence to sequence model which has been widely studied in machine translation . The problems we are keen on include  Code switch end to end and Adaptation -> how to improve the model in certain target environment (speaker, noise, type of dialogues), etc. Code-switch End-to-end  Classification-> what type of sound is this? Audio Scene and Event Analysis  Speaker id: who spoke it: speaker id under overlapping condition and when (Diarization).  Speech Enhancement - speaker extraction and derevberation .      Demos  Some of our previous works:    Youtube recordings: Our code-switch speech recognition in action:  Recognizing English\/Mandarin code-switch speech using our LVCSR system (2018 June).  Comparing our system against Google, Siri (2018 Sep).    Source separation - Separating Hillary Clinton and Trump voice from Youtube recording, from Chenglin's Demo slide (Oct 2018)  Speech indexing using our MAGOR system (Code-switch English\/Mandarin and Malay system)   See a demo of our ASR for ATC speech with NER highlighting. ATC with NER       Our recent demos using our speech engine  2020 FYPs demo:   Deploying Speech Recognition System using high availability and scalability kubernetes cluster Youtube  Chatbot framework using Dialog flow and various Q and A modules (2020 Demo) Youtube and a live demo Demo        Some of our recent works in git   PhD Student Hou Nana's work in NTU (2018~2021), single channel speech enhancement, github  PhD Student Xu Chenglin's work in NTU (2015~2020), single channel speech separation\/extration, github  Intern GeMeng's work (intern from Tianjin 2020~2021), tutorial speech separation, github  Intern Shangeths work (intern from BITS) (2020 Aug- 2021 June), Accent, Age, Height classification Pdf link  MSAI student Samuel Samsudin (2020~2021), emotion detection, github depository , kaggle iEmoCap  Language Identification by EEE's PhD student Liu Hexin (2021) github link  Intern Shashank Shirol's work (2020 Jan-June), using GAN to create noisy speech, github depository    "
},
{
  "id": "my_collaborator",
  "level": "1",
  "url": "my_collaborator.html",
  "type": "Section",
  "number": "2.2",
  "title": "Collaborators",
  "body": " Collaborators   Prof Li Haizhou , CUHK and AISG Speech Lab.  Prof Zhong Xionghu , Hunan University, China. Microphone Array DOA and diarization.  Dr Ma Bin , Alibaba. Robust End-to-End Code switch ASR.  Prof Huang Hao , Xinjiang University. PhD students exchange - Code switch ASR and classification.  Prof Xie Lei , Northwestern Polytechnic, Xian, China. PhD students exchange - ASR.  Prof Wang Longbiao , Tianjin University, China. PhD students exchange - Emotion recognition  Prof XI Wei , Xian JiaoTong University, China. CSC PhD students exchange - self-supervised learning     Past Collaborators   Dr Raphael Banchs , ChatBot.  Prof Lee Chin Hui , Robust ASR (~2008-2015)  Prof Tanja Schultz (~2008-2013) , Code-switch ASR    "
},
{
  "id": "my_Staff",
  "level": "1",
  "url": "my_Staff.html",
  "type": "Section",
  "number": "2.3",
  "title": "Staff",
  "body": " Staff   Dr Liu Hexin ,research fellow (LLM)  Ly Vu Thi ,Full-stack and chatBot  Ho Thi Nga , sentence unit detection and full-stack, backend.  Lim Zhi Hao Speaker verification and DNN  Kyaw Zin Tun (AISG-NTU) , full-stack development  Peng Yizhou (AISG-NUS) , speech research  Nabilah Ismail , Corpus Development  Nur Shahidah Binte Jamaludin , corpus development and linguistic support    Past Staff   Dr Rajendra Prasad Sirigina , Research Fellow, Time series, 2019 Feb-> 2021 June  Ma Duo (AISG-NUS) , LVCSR and classification, 2019-2021  Dr Pham Van Tung , Research Fellow, Speech recognition, end-to-end, keyword spotting, Jan 2012-2021 May  Dr Xu Haihua , Principal Research Fellow, Robust LVCSR, keyword spotting, Feb 2012-2021 March  Mai Trung Duc , full-stack and mobile app development, Mar 2019-Dec2021  Xu Chenglin , PhD (2020), Single Channel Multi-talker Speech Separation with Deep Learning  Zeng Zhiping , LVCSR, March 2018- April 2020  Ho Danyuan , corpus development and linguistic, May 2018-March 2020  Tian XiaoHai , TTS and voice morphing, part-time PhD and Staff, 2013-2018. Now in NUS.  Rao Wei , Speaker verification, 2015-2018, Now in NUS.  XiaoXiong , PhD Student 2004-2008, Staff 2008-2017, Now in Microsoft, Redmond - since Apr 2017  Benjamin Bigot , 2014-2016 - LVCSR for RR  Huang Guangpu , 2012-2015 - Articulatory Phonetics Features  Lyu Daucheng , 2009-2013 - Code switch LVCSR  Zhao Shengkui ,2009-2010 - Microphone array and beamforming.    "
},
{
  "id": "my_Students",
  "level": "1",
  "url": "my_Students.html",
  "type": "Section",
  "number": "2.4",
  "title": "Current PhD and Graduate Students",
  "body": " Current PhD and Graduate Students   Li Haoyang , Neural Text to Speech (reg Aug 2023, Alibaba-PhD)  Tuan Truong Duc , Robust Speaker verification under noisy and short duration scenario (reg Jan 2023, PhD)  Fabian Ritter Gutierrez ,End2End ASR for Language Learning (reg Aug 2022, AStar scholar) (co-supervised with AStar: Nancy Chen  Nikita Kuzmin , Disentaglement for Speaker verification and privacy (reg Aug 2022, AStar scholar) (co-supervised with AStar: Lee Kong Aik  Kwok Chin Yuen , Acoustic modelling of targetted domain speech (Children's speech acoustic modelling) (reg Aug 2021, MEng, converted to PhD program, Aug 2022)  Hu Yuchen 胡宇晨 , robust End-to-End ASR (reg Aug 2021, MEng, converted to PhD program, Aug 2022). QE Slides (2023) ,  Yip Jia Qi , Neural Networks for Speaker Extraction and its interdisciplinary applications (reg Aug 2021, Alibaba PhD)  Ng Dian Wen , Domain adaptation for End-to-End ASR (reg Jan 2021, Alibaba PhD)  Chen Chen , End-to-End ASR (reg Jan 2021, PhD)  Zou HeQing , Multimodal Machine Learning (reg Jan 2021, PhD) (Co-supervisor) (Sup:Deepu Rajan)  Rae Koh Jia Xin , Singapore English (reg Aug 2019, PhD)    Current MEng and Masters Program Students   Qin Xiaokai (2023 Aug~), MSAI student, Deepfake audio generation using voice conversion  Azmat Adnan (2023 Aug~), MSAI student, DNN Approaches for noisy speech diarization  Zhuo Ning (2023 Aug~), Masters Cybersecurity student, Deep Fake Corpus developmenet and detection     Collaborating graduate Student   Yang Yuhang (2023 June~, PhD student (Hunan University), China), LLM ASR  Zhang Xiangyu (2023 June~, PhD student (UNSW, Australia), Depression classification  Chen Weiguang (2022 June~, PhD student (Hunan University), Diarization using multi-channel approaches      Collaborating graduate Student (China)  Every year, we will host graduate students from China. We have hosted students from China Scholarship Council (program), Xinjiang University, Tianjin University and Northwestern University. The visits have been very rewarding, and many publications have come out of these visits. We hope to see more such outstanding students, so do apply!   Le Yuquan (2023 Oct~ Oct 2024, CSC visitor), PhD student (Hunan University, China), LLM for Legal  Luo Juan (2023 Oct~ Oct 2024, CSC visitor), PhD student (Hunan University, China), Audio event detection and classification  Bo Han (2023 Oct ~Oct 2024, CSC visitor), PhD student Zhejiang Uni, China), Deep Fake TTS audio generation  Zhao Yang (2021 Oct ~2023 Oct, CSC visitor, PhD student Xian JiaoTong Uni, China), Semi\/Self supervised representation for speech recognition  Peng Yizhou (2020 June ~2022 June, Masters student Xinjiang, China), ASR development (Kaldi and End2End)  Yang Yuhang (2021 June~2023 June, Masters student Xinjiang, China), WeNet ASR, End2End ASR  Guo Yachao (2021 June~2023 June, Masters student Xinjiang, China), End2End Hotword LM Adaptation     Past PhD Students    Andrew Koh Jin Jie , Sequence to Sequence Machine Learning (reg Aug 2019, PhD, submitted Thesis)  Zhao Yingzhu , End-to-End speech recognition (reg Jan 2019, PhD, graduated May 2023). Oral Defence rehearsal  PhD Slides  PhD report  PhD latex folder   Hou Nana , Robust LVCSR for air traffic control speech (reg Jan 2017, PhD, submitted Jan 2022)  Xu Chenglin , PhD Slides  PhD Thesis (2020) Single Channel Multi-talker Speech Separation with Deep Learning  Paul Chan , Synthesis of the human singing voice (2020)  Khassan Yerbolat , PhD Slides  , Online Presentation (April 2020) and final PhD thesis. , (2020) Language Model Domain Adaptation for Automatic Speech Recognition Systems.  Pham Van Tung , PhD Thesis  (2019) Robust Spoken Term Detection using partial search and re-scoring hypothesized detections techniques. Now in NTU.  Tian Xiaohai , PhD Thesis  (2019) Voice Conversion with Parallel\/Non-Parallel Data and Synthetic Speech Detection. Now in NUS.  Chong Tze Yuang , PhD Thesis , Slides , Thesis organization , (2018) Exploiting Long Context Using Joint Distance and Occurrence Informationfor Language Modeling.  Nguyen Duc Hoang Ha , PhD Thesis  (2017) Slides Feature based robust techniques for speech recognition.  Nguyen Trung Hieu , PhD Thesis  (2015). Speaker Diarization in Meeting room domain. Now at Alibaba.  Do Van Hai , PhD Thesis  (2015). Acoustic modelling of speech under limited training data condition. Now in Vietnam Telecoms.  Wu Zhizheng , PhD Thesis  (2015). Spectral Mapping for Voice Conversion.  Jonathan Dennis , PhD Thesis  (2014). Slides  , Sound Event Recognition in Unstructured Environments using Spectrogram Image Processing.  Wang Lei , (2013). Audio Pattern Discovery and retrieval.  Tong Rong , PhD Thesis  (2012). Towards high performance phonotactic features for spoken language recognition. Now at Alibaba.  Omid Dehzanghi , (2012). Discriminative Learning for speech recognition, U of Michigan  Xiao Xiong , PhD Thesis (2009)  . PhD Thesis: Robust speech features and acoustic models for speech recognition. QE (2006)  ,Speech Enhancement with Applications in speech recognition, now in Microsoft, US since Apr 2017  Wang Jinjun , PhD (2008), Content based sports video analysis and composition. Now in Xian Jiaotong.     Past MEng Students   Tanmay Surana , Deep Learning-based Text Augmentation for Named Entity Recognition (reg Aug 2021, MEng, completed Oct 2023)  Prachaseree Chaiyasait , Adaptation of Language Models via Text Augmentation (reg Aug 2021, MEng, submitted Jul 2023, completed Oct 2023)  Kyaw Zin Tun , Name entity recognition for chatbot applcications(MEng, started Aug 2020, submitted thesis Aug 2022)  Xue Fuzhao , Information extraction from text (MEng 2020)  Lim Zhi Hao , (MEng 2020), Anti-Spoofing Techniques for Robust Speaker Verification Thesis (2020)  Ho Thi Nga , (MEng 2019), Sentence unit detection for automatic speech transcripts using lexical information  Leow Sujun , (MEng 2018), Image Processing Technique for Speech Signal Processing  Nguyen Quy Hy , (MEng 2017), Voice conversion using DNN  Steven Du , (MEng 2015), Robust Front End for Speaker Verification  Terrence Ng Wen Zheng , Thesis ,(MEng 2014), Sound Event recognition in home environment  Chen Wenda , (MEng 2014),Computer Assisted Language Learning  Ben Pham Chau Khoa , Thesis ,(MEng 2012), Robust VAD  Eugene Koh, (MEng 2009), Speaker Diarizaton     Past MSAI Students and Other collaboration students   Jiang Yufei (2022 Aug~ 2023 Aug), MSAI (NTU), Adopting Neural Translation Model in Data Generation for Inverse Text Normalization  Liu Jiaxing (2021 Oct ~2023 Oct, CSC visitor, PhD student Tianjin University, China), Multi-modal emotion recognition  Cheng Qi (2021 Oct ~2022 Oct, CSC visitor, PhD student Harbin Engineering Uni, China), Graph Neural Network for Lattice rescoring  Samuel Samsudin Ng , (MSAI 2020-S1), Speech emotion recognition with AlexNet and Fully convolutional network, Sam's MSAI Thesis , github depository , kaggle iEmoCap   Cheung Chin Ka , (MSAI 2020-S1), Acoustic Scene Classication with cutting edge hyperparameter tuning tool, Andy's MSAI Thesis   Liu Bozhong , (MSAI 2020-S2), Wakeup keyword detection for far-field microphone array using end to end framework  "
},
{
  "id": "Past_Interns",
  "level": "1",
  "url": "Past_Interns.html",
  "type": "Section",
  "number": "2.5",
  "title": "Internship in Speech Lab@SCSE, NTU",
  "body": " Internship in Speech Lab@SCSE, NTU   We have a tradition of hosting senior undergraduate students (final year) and graduate students (Masters and PhD) in our lab.  Typically we only host students who can work with us for 6 months or more in 2 sessions. Session 1: Jan-June, Session 2: Jul->Dec each year. During covid (it will be remote), and if NTU allows student to come to Singapore, we will prefer you to be physically in our lab. Currently we only host students who are doing this as part of their course sanctioned by their school and its graded *so its not a personal arrangement*.  To apply, you should be writing to us at least 1\/2 year before the start of the attachment. Kindly send me an email with a detailed cv. As we receive huge number of applicants, only shortlisted students will receive a response.  We have two tracks, one for research and the other for development. For research, we expect students to have work with pyTorch, tensorflow, etc. For development, we expect experiene with google summer of code, full stack experience. During this internship, you will be actively working with our speech-team researchers on tasks such as implementing and realising state-of-the-art ML\/DL techniques and deploying them for various tasks listed below:   Our current Research projects are:  DNN and End-to-end approaches for speech audio processing and classification   Classification from Audio: Speaker profiling (age, height, weight, accent, emotion) classification, Audio Event classification (DCASE), Speaker diarization and overlapping speech detection  Speech Enhancement and Audio processing: Enhancing noisy speech to clean DNN approaches, Deep Fake Speech: Modifying audio eavefiles to target environment\/speaker\/ noise using GAN   Our current Development projects are:   Terraform and cloud deployment of speech engine with scaling, auto-update, security and dashboard.  MAGOR - search and indexing speech, video and audio  Async speech recording and recognition Interface - recording and async update of speech recognised with update on name entity  Transcriptor - GUI for correction of erroneous recognised text   Upon completion of the project, we expect a formal project report + code repository, and if possible submit the work for publication.  Pls find attached a writeup by Shashank (2021 intern) onboarding help file, have a look. Onboarding writeup by Shashank   Current and Past Interns:  The list is incomplete, we began to the tradition of taking pictures with the students from India about 2017, there were many others. The pictures here mainly are undergraduate students, and details included inside.   2023 June~Dec(fully remote)  Some pictures of our group meetings with Interns from 2023(fully remote)  Some pictures of our group meetings with Interns from 2022(fully remote)  Some pictures of our group meetings with Interns from 2021(fully remote)  Interns from 2020 (July-Dec) (fully remote)  Interns from 2020 (Jan-May) (our last group before we could not have students in Singapore)  Interns from 2019 (Nov, Grp1)  Interns from 2019 (Nov, Grp2)  Interns from 2019 (Jul)  Interns from 2019 (Apr)  Interns from 2018 (Oct)  Interns from 2018 (Jul)  Interns from 2018 (May)  Interns from 2018 (Jan)  Interns from 2017 (Jul)  Gangeshwar Krishnamurthy,2017 (Jan-Apr)  Gao Shengheng,2016 (Mar-Jun)   "
},
{
  "id": "GraduateStudents",
  "level": "1",
  "url": "GraduateStudents.html",
  "type": "Section",
  "number": "3.1",
  "title": "Graduate Students",
  "body": " Graduate Students  This section provides some tips for incoming graduate students - from thesis writing, useful tools, guide to responding to examiners, etc.  If you are feeling lost about research, or doing research for the first time, heres a short note that may help Tips to new research students. You can also read about JHU's Prof Dredze's guide for \"Guide on How to be a Successful PhD Student\"    SCSE Thesis formatting requirements   Template for NTU thesis: GitHub URL: link  A 2020 example of NTU PhD thesis (required front\/back matters and formatting) in SCSE, see SCSE thesis suggestion      NTU TAC report example   For TAC reporting, heres an example from my PhD student Hou Nana (Oct 2020) submitting this to her TAC panel for their endoresement. Link here TAC HOU Nana (2020)      Yearly reporting to TAC  You will need meet up with your TAC yearly. They are responsible to discuss with you your progress. Hence you will need to arrange for a meeting with them together, or individually. Sometimes they can ask you to send them your slides to present to them, or writeup. If they are comfortable with your progress, they can then help to sign off. If they are unable to meet you, You can also record a 20~30 mins presentation and send them to watch the video. Basically, your presentation to them, pls update:  Your CGPA  Updated publications  progress in research (like a QE presentation, or Phd thesis presentation) ~ about 15~20 mins  Future research plans\/goals.      Writing and Presenting for Graduate Students   My take in how you can organize your thesis, as well as presentation slides for your PhD defence (QE is the same).  Tips about writing thesis: word document and main map  I consider structure to be the most important consideration. To have structure, first write a series of questions to drive the report (revise it many times), and with the (finalised) questions, generate a power point file to provide more contents towards answering the questions. Repeat until satisfied, and then write the report. See Chong's example below as well as PhD ProofReader's template (see below) Writing Template  Use ChatGPT to help improve your writing. See: ChatGPT Promots as well as YouTube: Epic ChatGPT Prompts (to help research writing)  Example, how to prepare for QE: have a look at Zhao Yingzhu's (2020) and Andrew Koh's (2021) Qualifying Exam (QE) preparation (details below).  Example, how to prepare for PhD presentation (typically 40-45 mins), see Khassan's example below.    Chong Tze Yuang preparation for his PhD thesis (2018): List of questions and Power point preparations for thesis and thesis and Presentation Slides     Khassan Yerbolat 's experience for his QE and PhD presentation:  QE preparation: List of Questions and Initial Draft QE   Khassan's final PhD thesis , and an example of reply , for examiner.  During COVID lockdown (April 2020) he presented his PhD defence. The presentation was clear, and coherent. See the Questions used to guide its development, Slides and finally the Online Presentation .     Zhao Yingzhu preparation for her QE thesis (July 2020): Preparation Suggestions and QE Presentation Slides and Youtube Link presentation and Thesis   Andrew Koh Jin Jie's github for QE preparation for his QE thesis, slides, and presentation (May 2021).      Guideline for Responses to examiner and journal  This section suggests how to respond to examines for your PhD thesis revisions as well as responses to journal for revisions. In short, you have to be clear, state if you agree or disagree, reply appropriately with depth and indicate where the changes are made. This allows the reviewer to quickly go through all the points to endorse or reject your resubmission.   Example replies to Examiner in SCSE PhD thesis revision: Great example of a good response  Khassan's response for PhD revision (see above for his thesis, presentation, etc): reply , for examiner.  Andrew Koh's response (Nov 2023) for PhD thesis: reply , for examiner.  An example in IEEE Trans antenna: response  An example by Steven Atkinson (U of Queensland, CS) pdf paper  A template (remember you need to cross ref in detail to your revision (where are the changes)) template      Tools for writing   Please use latex for your writing - it will help a lot! In windows you have miktex . You can get a host of templates here. My editor of choice is TexStudio - but ask Quora for the latest answer.  If you need to watch a youtube video on latex, see overleaf latex  For drawing, you can try draw.io its a very nice software.  For collating all your papers, try mendely , or zotero.  To link all your ideas, I am now trying obsidian , and some of my student prefer roamresearch . I also use iThoughtsHD to generate mindmaps in my iPad.   Jonathan Dennis experience: tip on tools he used for writing thesis.     Tools to organize your work   notion: keep your notes notion  MindMap: organize your thoughts with Obsidian.md , Roam Research , or iThoughtsHD .  Using Google CoLab     Writing Advise from others   PhD Proof Reader - how to write an abstract and other resources - writing abstract , knowledge base , Writing Template  American Graduate School suggestion - guidelines  Karpathy's writing on \"A survival guide to a PhD\" - link  Karpathy's \"Doing well in a course\" - link  Kristin Sainani - writing for the sciences youtube link  Professor Simon Peyton Jones (Cambridge) - How to write a Great Research Paper youtube Link .  Judy Swan (Princeton) - Scientific Writing youtube Link .  Steve Easterbrook - how thesis get written. \\href{}{Youtube}    Subjects, Software you should know  A list of subjects you can and should pick up before starting your graduate school with speech lab: see list of things to know   "
},
{
  "id": "UndergraduateStudents",
  "level": "1",
  "url": "UndergraduateStudents.html",
  "type": "Section",
  "number": "3.2",
  "title": "UnderGraduate Students",
  "body": " UnderGraduate Students   FYP (Final Year Project) presentation matters  FYP presentation information: FYP presentation requires you to speak for about 20~23 minutes with additional 5 minutes of Q and A. The objective of the presentation is for the examiner to understand and appreciate what you have done, hence in the presentation you should  Present an Overview of the problem – what is the problem, motivation to solve the problem, existing issues of the problem.  Discuss Who\/how has the problem been solved by others (lit survey).  Present how you have solved the problem – novelty, difficulty, creativity, etc.  Show the results (demo, screen shot, experiment, table, video) of your work.  Finally, present conclusion and future works.    Note: For your slides: page 1 MUST have your name, FYP title, year of FYP, etc and all slides must have page number.  Note, the motive of the presentation is for the examiner to grade you, hence he\/she has to appreciate your FYP, your work (difficulty, your contribution), and your technical ability, coding skill, knowledge, etc. You should have a lot of good things to say about the great things you have done, but remember you only have 20~25 minutes.  To prepare, I suggest you make a video of your own presentation and watch it as rehearsal. See examples of previous students FYP presentation in the section below.    FYP final report and interim report  Pls write your report in Overleaf Latex.  FYP report (interim) and (final): the purpose of the report is to show that you  your project scope (problem) and what you have accomplished.  have done the work by yourself (no cut and paste), able to describe the technology and steps taken to complete the project  have sufficient knowledge of the work (lit review, discussions)  implemented reasonable baselines (codes, demos, etc)  proposed future works    The interim report should look like a 50% version of the final report, and you can look at the examples in the next section. Final report should be in the range of 40~65 pages  See the advise for writing here: , same applies.    Examples of past FYP reports, presentations, etc    2023 Dec example by Tjandy Putra- : Deploying Automatic Speech Recognition System for scalability, reliabiliy and security with Kubernetics. Video Link , Pdf Report  Slides   2023 May example by Christopher Yong - Web-Based Speech Recognition Platform (On Cloud and Local Deployment) Video Link , Pdf Report  Slides   2023 May exampl by Song Yu - Deploying Speech Recognition System using Kubernetes Cluster Infrastructure as Code with Terraform and Terragrunt Video Link  , Pdf report   Slides   2022 Dec example by Poh Kai Kiat - GitOps in Kubernetics Cluster YouTube Link , FYP Report  2022 May example by Joshua Lee - Docker and Kubernetes – Enhance the securities of the live-stream ASR system deployment in the cloud Slides , report ,  Youtube  2022 May example by Tan Hui Zhan: Web-based Speech Recognition Platform – SG Decoding Slides , report , Youtube  2021 Dec example by Lee Yan Zhen - sound event detection with human and emergency sounds Youtube , slides , report  2020-Dec example by Darren Toh - Multipurpose microphone array system Youtube  May 2020 - Wong Seng Wee's FYP - Deploying Speech Recognition System using high availability and scalability kubernetes cluster Youtube  Some past example of expected standard of report: here   Examples in NTU library for web application\/development type of projects: 148069 , 153133 , 148042 , 148427    "
},
{
  "id": "Teaching-4",
  "level": "1",
  "url": "Teaching-4.html",
  "type": "Section",
  "number": "3.3",
  "title": "Courses Taught",
  "body": " Courses Taught    CPE3007 - Digital Signal Processing (Since 2013):  Videos for this subject by me (2018): YouTube link  Some code samples for DSP python (2018) by me. Github Link     CPE414\/ES6105 DSP (2005-9)  CPE3006 - Digital Communications (since Jan 2016 - 2017)  CPE206 - Micro-controller Systems Design (2004-2009)  Maths2 - (tut-2018 Jan, lecture 2019)   "
},
{
  "id": "Teaching-5",
  "level": "1",
  "url": "Teaching-5.html",
  "type": "Section",
  "number": "3.4",
  "title": "Some relevant E-Learning Videos",
  "body": " Some relevant E-Learning Videos   Weighted Finite State Transducer - YouTube produced by Lim Zhi Hao in 2015 during his TL internship.  Tensors for Beginners by eigenchris (pg?ug), Youtube  Essence of Linear Algebra by 3Blue1Brown (ug) an intutive understanding, Youtube  Petra Bonfert-Taylor's lectures (ug) Analysis of a Complex Kind Youtube  Stephen Boyd, ECE263, Intro to Linear Dynamical System (pg?ug) YouTube  Ole Chirstensen lectures - Hilbert Space (pg) YouTube  Fredric Schuller's lectures - Hilbert Space and such (pg) YouTube    "
},
{
  "id": "Current_Fundings",
  "level": "1",
  "url": "Current_Fundings.html",
  "type": "Section",
  "number": "4.1",
  "title": "Current Fundings",
  "body": " Current Fundings   Jul 2021 - Jul 2024, Project ISSAC, DSO, Amount S$941K, PI  Mar 2021 - Apr 2023, Project SenseMaking, ST Engineering, Amount: S$912K, PI  Oct 2020 - Oct 2022, Project ISCAP , DSO, Amount: S$330K, PI  Jul 2020 - Jul 2021, Conversational Bahasa Indonesia Speech Recognition using State of the Art ASR Techniques, Webank, Amount: S$100K, PI  Sep 2019 - Sep 2021, Project MAISON 2 , DSO, Amount: S$600K, PI  Jan 2019 – Dec 2021, DACS3.1: AI for Smart Discovery, Roll-Royce Corp Lab, PI (S$1.366M Cash+in-kind)  Oct 2018 - Sep 2021, Alibab-NTU Singapore joint lab - Code-switch speeech recognition (Amount S$272K + 2 PhD students) , PI  Jul 2018 Jun – Dec 2022 Jun AISG 100E-2018-006 “AI-Speech Lab: Automatic Speech Recognition for Public Service”, Co-PI NTU (S$600K+Cofunding)   "
},
{
  "id": "Past_Fundings",
  "level": "1",
  "url": "Past_Fundings.html",
  "type": "Section",
  "number": "4.2",
  "title": "Past Fundings",
  "body": " Past Fundings   Apr 2018 Apr – Apr 2020 Apr, The Development Of Processes And SDKs To Support The Deployment Of Speech Recognition And Keyword Spotting Technologies For KLASS Engineering, PI, S$660K  Jan 2018 - Jan 2020, Project Malvin, Mindef, Amount: S$600K, PI  Jul 2017 - Jul 2019, Project Creton, Mindef, Amount: S$780K, PI-Track2  Nov 2016 - Nov 2018, Project Acumon, Mindef, Amount: S$560K, PI  Jan 2016 1 RSS from ATMRI-NTU for PhD student Hou Nana, Robust ASR for very noisy speech in air-traffic control domain, (Amount:S$200K) ATMRI-NTU, PI  Jun 2014 - Jun 2017, Project Maison: Robust Speaker Verification And Keyword Spotting, DSO M4061477, Amount: S$2.2 million, PI.  Mar 2014 - Jul 2018, RT1.2: Smart Visual Analytics of unconventional data NRF and Rolls Royce Project, Amount: S$777K, PI  Mar 2014 - Jul 2018, RT1.1: Smart Knowledge Discovery from unconventional data, NRF and Rolls Royce, Amount: S$872K (75\\%-PI), PI  Apr 2013 - Apr 2015, Development of Linguistic Resources and LVCSR for Southeast Asia Languages on KALDI platform (DeKALDI) AStar, S$124,800, PI  Sep 2011 - Aug 2014, Audio Mining Broadcast News, DSTA: M4060890.683, S$500K, PI  Jan 2010 - Dec 2011, Merlion 2009, MultiLing, French Embassy (Singapore), S$30K, PI  July 2010 - Jun 2012, Speech Recognition for Code-switch Conversational Speech, Temasek Lab@NTU, ProjectID: M48680100, Amount: S$200K, PI  Mar 2010 - Feb 2012, A pilot study of a Computer Assisted Pronunciation Evaluation (CAPE) system for English learners in Singapore, MOE Tier 1 ProjectID: M52020089, Amount: S$190K, PI-Chng Eng Siong, Co-PI: Tan Ying Ying  Nov 2009-Oct 2010, Malay Text-to-Speech Synthesis Astar ProjectID: M48020073, Amount: S$90K  Nov 2009 - Oct 2011, A Microphone Array with a 3-dimensional configuration for the I2R social robot, AStar ProjectID: M48020074, Amount: S$200,400  Dec 2008, Attachment to Tokyo Institute of Technology, Japan to visit Prof S. Furui Lab for exchange in speech research, NTU\/NUS-JSPS New Scientific Exchange Programme (NSEP). Amount: S$3K, PI  Sep 2008 - Mar 2010, Statistical Language Modeling for spoken document retrieval Astar ProjectID: M48020061, Amount: S$240K, PI  Apr 2008 - Oct 2008, Speech Channel Modelling and Classification, Astar ProjectID: M48020050, Amount: S$108K, PI  Mar 2008 - Feb 2013 Advanced Research in Automatic Speech Recognition, Temasek Lab@NTU, ProjectID: M48680101, Amount: S$1 million, PI: Li Haizhou, Co-PI: Chng Eng Siong  Jan 2008 - Jun 2008 Robust Speech Signal Acquisition and Enhancement, AStar ProjectID: M48020049, Amount: S$72,000, PI.  Dec 2007 - Dec 2009 Micro-eBlock: A scalable microcomputer peripheral system for tertiary level micro-controller education, MOE, NTU and Renesas, Amount: S$313,572, ProjectID: M20440011, Co-Principal Investigators: Chng Eng Siong and Tan Su Lim  Jun 2007 - July 2007, Tan Chin Tuan Fellowship. Attachment to Tsinghua University, Beijing, China, Amount: S$6000 PI.  Jun 2007 - Jun 2008, Speech Data Collection Technology for Robotic Dialog Application Astar ProjectID, M48020040, Amount: S$69,920, PI.  July 2006, ROAR 2006 Award, 1 PhD studentship, NTU Award: Approx S$100K, PI.  Feb 2007 - Feb 2008, Supplementary Equipment Purchase, Digital Signal Processing for Voice Enhancement Recognition and Search, NTU Award: ProjectID:: M52020057, Project Ref number: RG129\/06, Amount: S$39,440, PI.  Mar 2006-Mar 2007, Development of Speaker turn library for I2R AStar, Project ID: M48020025, Amount: S$70,000, PI.  Sep 2004- July 2010, Digital Signal Processing for Voice Enhancement, Recognition and Search: AStar G\/L Acct: 500360, Amount: S$138,000, PI.  Oct 2004 - Mar 2005, Summarization of proceedings in a Smart Meeting Rooms for AStar Thematic Pilot project, AStar M47020015, SERC grant number: 0421110063, Amount: S$21,000 Chng Eng Siong and Deepu Rajan  Jun 2003 - Jun 2004, Collaborative acoustic sensor for a smart meeting room application. NTU, SCE CE-SUG-01\/03 Amount: S$14,600, PI  Dec 2003 - Jan 2004, 2 months, Overseas Attachment programme to University of Southampton, Dept of ECE. Attachment to Prof Sheng Chen AStar Award, Amount: S$3600, PI   "
}
]

var ptx_lunr_idx = lunr(function () {
  this.ref('id')
  this.field('title')
  this.field('body')
  this.metadataWhitelist = ['position']

  ptx_lunr_docs.forEach(function (doc) {
    this.add(doc)
  }, this)
})
