<!DOCTYPE html>
<!--**************************************-->
<!--*    Generated from PreTeXt source   *-->
<!--*    on 2025-08-20T10:37:30+08:00    *-->
<!--*                                    *-->
<!--*      https://pretextbook.org       *-->
<!--*                                    *-->
<!--**************************************-->
<html lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Current PhD and Graduate Students</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width,  initial-scale=1.0, user-scalable=0, minimum-scale=1.0, maximum-scale=1.0">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [['\\(','\\)']]
    },
    asciimath2jax: {
        ignoreClass: ".*",
        processClass: "has_am"
    },
    jax: ["input/AsciiMath"],
    extensions: ["asciimath2jax.js"],
    TeX: {
        extensions: ["extpfeil.js", "autobold.js", "https://pretextbook.org/js/lib/mathjaxknowl.js", "AMScd.js", ],
        // scrolling to fragment identifiers is controlled by other Javascript
        positionToHash: false,
        equationNumbers: { autoNumber: "none", useLabelIds: true, },
        TagSide: "right",
        TagIndent: ".8em",
    },
    // HTML-CSS output Jax to be dropped for MathJax 3.0
    "HTML-CSS": {
        scale: 88,
        mtextFontInherit: true,
    },
    CommonHTML: {
        scale: 88,
        mtextFontInherit: true,
    },
});
</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_CHTML-full"></script><script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.13/pretext.js"></script><script src="https://pretextbook.org/js/0.13/pretext_add_on.js"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.31/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.31/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.31/banner_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.31/toc_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.31/knowls_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.31/style_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.31/colors_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.31/setcolors.css" rel="stylesheet" type="text/css">
<!-- 2019-10-12: Temporary - CSS file for experiments with styling --><link href="developer.css" rel="stylesheet" type="text/css">
</head>
<body class="mathbook-book has-toc has-sidebar-left">
<a class="assistive" href="#content">Skip to main content</a><div class="hidden-content" style="display:none">\(
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\)</div>
<header id="masthead" class="smallbuttons"><div class="banner"><div class="container">
<a id="logo-link" href="https://www.ntu.edu.sg/home/aseschng/default.html" target="_blank"><img src="images/ntu_img.png" alt="Logo image"></a><div class="title-container">
<h1 class="heading"><a href="default.html"><span class="title">Chng Eng Siong</span></a></h1>
<p class="byline"></p>
</div>
</div></div>
<nav id="primary-navbar" class="navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active" aria-label="Show or hide table of contents sidebar">Contents</button><div class="tree-nav toolbar toolbar-divisor-3"><span class="threebuttons"><a id="previousbutton" class="previous-button toolbar-item button" href="my_Staff.html" title="Previous">Prev</a><a id="upbutton" class="up-button button toolbar-item" href="SpeechLab.html" title="Up">Up</a><a id="nextbutton" class="next-button button toolbar-item" href="Past_Interns.html" title="Next">Next</a></span></div>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="my_Staff.html" title="Previous">Prev</a><a class="up-button button toolbar-item" href="SpeechLab.html" title="Up">Up</a><a class="next-button button toolbar-item" href="Past_Interns.html" title="Next">Next</a>
</div>
</div></nav></header><div class="page">
<div id="sidebar-left" class="sidebar" role="navigation"><div class="sidebar-content">
<nav id="toc"><ul>
<li class="link"><a href="intro1.html" data-scroll="intro1"><span class="codenumber">1</span> <span class="title">Introduction</span></a></li>
<li class="link">
<a href="SpeechLab.html" data-scroll="SpeechLab"><span class="codenumber">2</span> <span class="title">Speech and Language Laboratory</span></a><ul>
<li><a href="speechLab_intro.html" data-scroll="speechLab_intro">Speech and Language laboratory</a></li>
<li><a href="my_collaborator.html" data-scroll="my_collaborator">Collaborators</a></li>
<li><a href="my_Staff.html" data-scroll="my_Staff">Staff</a></li>
<li><a href="my_Students.html" data-scroll="my_Students" class="active">Current PhD and Graduate Students</a></li>
<li><a href="Past_Interns.html" data-scroll="Past_Interns">Internship in Speech Lab@SCSE, NTU</a></li>
</ul>
</li>
<li class="link">
<a href="Teaching.html" data-scroll="Teaching"><span class="codenumber">3</span> <span class="title">Teaching Activities</span></a><ul>
<li><a href="GraduateStudents.html" data-scroll="GraduateStudents">Graduate Students</a></li>
<li><a href="UndergraduateStudents.html" data-scroll="UndergraduateStudents">UnderGraduate Students</a></li>
<li><a href="section-8.html" data-scroll="section-8">Courses Taught</a></li>
<li><a href="section-9.html" data-scroll="section-9">Some relevant E-Learning Videos</a></li>
</ul>
</li>
<li class="link">
<a href="FundlingList.html" data-scroll="FundlingList"><span class="codenumber">4</span> <span class="title">Fundings</span></a><ul>
<li><a href="Current_Fundings.html" data-scroll="Current_Fundings">Current Fundings</a></li>
<li><a href="Past_Fundings.html" data-scroll="Past_Fundings">Past Fundings</a></li>
</ul>
</li>
</ul></nav><div class="extras"><nav><a class="mathbook-link" href="https://pretextbook.org">Authored in PreTeXt</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a></nav></div>
</div></div>
<main class="main"><div id="content" class="pretext-content"><section class="section" id="my_Students"><h2 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber">2.4</span> <span class="title">Current PhD and Graduate Students</span>
</h2>
<a href="my_Students.html" class="permalink">¶</a><ol id="p-36" class="decimal">
<li id="li-81">
<a class="external" href="https://www.linkedin.com/in/yi-wen-chao-407277295/" target="_blank"><code class="code-inline tex2jax_ignore">Chao Yi-Wen</code></a>, Paralinguistics-enhanced LLM for Spoken Dialogue System  (PhD reg Aug 2024, Supervisor: Chng Eng Siong, AStar: Lu Yanfeng)</li>
<li id="li-82">
<a class="external" href="https://www.linkedin.com/in/songting-liu-b0098b220/" target="_blank"><code class="code-inline tex2jax_ignore">Liu Songting</code></a>, Voice Conversion  (MEng reg Aug 2024, Supervisor: Chng Eng Siong)</li>
<li id="li-83">
<a class="external" href="https://www.linkedin.com/in/%E4%BE%9D%E8%B1%AA-%E5%90%B4-0b5523325/" target="_blank"><code class="code-inline tex2jax_ignore">Wu Yihao</code></a>, Approaches for Diarization  (MEng reg Aug 2024, Supervisor: Chng Eng Siong)</li>
<li id="li-84">
<a class="external" href="https://www.linkedin.com/in/yeoyueheng" target="_blank"><code class="code-inline tex2jax_ignore">Yeo Yue Heng</code></a>, LLM for speech recognition (PhD reg Jan 2024, Supervisor: Chng Eng Siong, AStar Co-Sup:Tran Huy Dat), AStar Scholar</li>
<li id="li-85">
<a class="external" href="https://www.linkedin.com/in/davisl44622" target="_blank"><code class="code-inline tex2jax_ignore">Li Haoyang</code></a>, Neural Text to Speech (PhD reg Aug 2023)</li>
<li id="li-86">
<a class="external" href="https://www.linkedin.com/in/ductuantruong/" target="_blank"><code class="code-inline tex2jax_ignore">Tuan Truong Duc</code></a>, Robust Speaker verification and Deep Fake Detection under noisy and short duration scenario (reg Jan 2023, PhD)</li>
<li id="li-87">
<a class="external" href="https://www.linkedin.com/in/fabian-ritter-gutierrez-9ab4317a/" target="_blank"><code class="code-inline tex2jax_ignore">Fabian Ritter Gutierrez</code></a>,End2End ASR for Language Learning (PhD, reg Aug 2022, AStar scholar) (co-supervised with AStar: Nancy Chen. QE (2024):  <a class="external" href="https://github.com/FabianRitter/NTU_QE_PRESENTATION/tree/main" target="_blank"><code class="code-inline tex2jax_ignore"> Github of Thesis and Video</code></a>
</li>
<li id="li-88">
<a class="external" href="https://www.linkedin.com/in/paniquex/" target="_blank"><code class="code-inline tex2jax_ignore">Nikita Kuzmin</code></a>, Disentaglement for Speaker verification and privacy (PhD, reg Aug 2022, AStar scholar) (co-supervised with AStar: Lee Kong Aik. <a class="external" href="https://github.com/paniquex/PHD_QE_NTU" target="_blank"><code class="code-inline tex2jax_ignore">QE: 2025 </code></a>
</li>
<li id="li-89">
<a class="external" href="https://www.linkedin.com/in/aaron-kwok-b1163b1b4/" target="_blank"><code class="code-inline tex2jax_ignore">Kwok Chin Yuen</code></a>, Acoustic modelling of targetted domain speech (Children's speech acoustic modelling) (reg Aug 2021, MEng, converted to PhD program, Aug 2022)</li>
<li id="li-90">
<a class="external" href="https://yuchen005.github.io/" target="_blank"><code class="code-inline tex2jax_ignore">Hu Yuchen 胡宇晨 </code></a>, robust End-to-End ASR (reg Aug 2021, MEng, converted to PhD program, Aug 2022, Thesis submitted: June 2025). <a class="external" href="https://www.dropbox.com/scl/fi/4max4uevisy2agmz29or0/2023_HuYuchenQE_QE_presentation.pptx?rlkey=bbrrdv0h042wi4b23gah2r3ct" target="_blank"><code class="code-inline tex2jax_ignore">QE Slides (2023)</code></a>,</li>
</ol>
<section class="subsection" id="my_co_sup_Students"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">2.4.1</span> <span class="title">Current Co-Sup: PhD Students</span>
</h3>
<a href="my_Students.html#my_co_sup_Students" class="permalink">¶</a><ol id="p-37" class="decimal">
<li id="li-91">
<a class="external" href="https://www.linkedin.com/in/ashutosh-anshul-b12508148" target="_blank"><code class="code-inline tex2jax_ignore">Ashutosh Anshul</code></a>, Multi-modal Deep Fake classification and detection (reg Jan 2024, Supervisor: Deepu Rajan, Co-Sup:Chng Eng Siong)</li>
<li id="li-92">
<a class="external" href="https://www.linkedin.com/in/the-shreyas-gopal/" target="_blank"><code class="code-inline tex2jax_ignore">Shreyas Gopas</code></a>, Speech Recognition using LLM for under-resourced languages (reg Jan 2024, Supervisor: Quek Hiok Chai, Co-Sup:Chng Eng Siong)</li>
</ol></section><section class="subsection" id="my_MSAI_Students"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">2.4.2</span> <span class="title">Current MEng and Masters Program Students</span>
</h3>
<a href="my_Students.html#my_MSAI_Students" class="permalink">¶</a><ol id="p-38" class="decimal">
<li id="li-93">
<a class="external" href="https://www.linkedin.com/in/%E4%BE%9D%E8%B1%AA-%E5%90%B4-0b5523325/" target="_blank"><code class="code-inline tex2jax_ignore">Wu Yihao</code></a>, Robust diarization for large scale meeting scenario  (MEng reg Aug 2024, Supervisor: Chng Eng Siong)</li>
<li id="li-94">
<a class="external" href="https://www.linkedin.com/in/yunyi-ni-3a6885325/?original_referer=https%3A%2F%2Fwww%2Egoogle%2Ecom%2F?originalSubdomain=sg" target="_blank"><code class="code-inline tex2jax_ignore">Ni Yunyi</code></a>, VoiceForge: A Text-Driven Character Voice Generation System for Narrative Content Creation (MSAI reg Aug 2024, Supervisor: Chng Eng Siong)</li>
<li id="li-95">
<a class="external" href="https://www.linkedin.com/in/skandml/?originalSubdomain=sg" target="_blank"><code class="code-inline tex2jax_ignore">Thirunavukarasu Suresh Sathya Krishnan</code></a>, Advancing Dialogue Systems: Synthetic Dialogue Generation and Code-Switching in LLMs (MSAI reg Aug 2024, Supervisor: Chng Eng Siong)</li>
</ol></section><section class="subsection" id="my_collaborator_Students_China"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">2.4.3</span> <span class="title">Collaborating graduate Student (China)</span>
</h3>
<a href="my_Students.html#my_collaborator_Students_China" class="permalink">¶</a><p id="p-39">Every year, we will host graduate students from China. We have hosted students from China Scholarship Council (program), Peking University, Xinjiang University, Hunan University, Tianjin University and Northwestern University. The visits have been very rewarding, and many publications have come out of these visits. We hope to see more such outstanding students, so do apply!</p>
<ol id="p-40" class="decimal">
<li id="li-96">
<a class="external" href="https://arxiv.org/abs/2311.17382" target="_blank"><code class="code-inline tex2jax_ignore">Yang Yuhang</code></a> (2023 June~, PhD student (Hunan University), China), LLM ASR</li>
<li id="li-97">
<a class="external" href="https://www.linkedin.com/in/xiangyu-zhang-a0735b194/" target="_blank"><code class="code-inline tex2jax_ignore">Zhang Xiangyu</code></a> (2023 June~, PhD student (UNSW, Australia), Depression classification</li>
<li id="li-98">
<code class="code-inline tex2jax_ignore">Chen Weiguang</code> (2022 June~, PhD student (Hunan University), Diarization using multi-channel approaches</li>
<li id="li-99">
<a class="external" href="https://scholar.google.co.uk/citations?user=KjcXd6cAAAAJ" target="_blank"><code class="code-inline tex2jax_ignore">Yao Jixun</code></a> (2023 Oct~ Oct 2024, AISG NUS visitor), PhD student (Northwestern Poly, China), Speech Enhancement and TTS</li>
<li id="li-100">
<a class="external" href="https://scholar.google.com/citations?user=GEVwy4sAAAAJ" target="_blank"><code class="code-inline tex2jax_ignore">Le Yuquan</code></a> (2023 Oct~ Oct 2024, CSC visitor), PhD student (Hunan University, China), LLM for Legal</li>
<li id="li-101">
<code class="code-inline tex2jax_ignore">Luo Juan</code> (2023 Oct~ Oct 2024, CSC visitor), PhD student (Hunan University, China), Audio event detection and classification</li>
<li id="li-102">
<a class="external" href="https://arxiv.org/abs/2305.10761" target="_blank"><code class="code-inline tex2jax_ignore">Zhang Zizheng</code></a> (2023 June~ Jun 2024, AISG remote), Masters student (Peking University, China), Speech Separation, <a class="external" href="https://github.com/TzuchengChang/NASS" target="_blank"><code class="code-inline tex2jax_ignore">github</code></a>
</li>
<li id="li-103">
<a class="external" href="https://openreview.net/profile?id=~Haorui_Zheng1" target="_blank"><code class="code-inline tex2jax_ignore">Zheng Haorui</code></a> (2024 June~ , AISG remote), Masters student (Peking University, China), Speaker Diarization with Speech Separation</li>
<li id="li-104">
<a class="external" href="https://github.com/fluide1022" target="_blank"><code class="code-inline tex2jax_ignore">Bo Han</code></a> (2023 Oct ~Oct 2024, CSC visitor), PhD student Zhejiang Uni, China), Deep Fake TTS audio generation</li>
</ol></section><section class="subsection" id="Past_PhD_Students"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">2.4.4</span> <span class="title">Past PhD Students</span>
</h3>
<a href="my_Students.html#Past_PhD_Students" class="permalink">¶</a><div class="image-box" style="width: 100%; margin-left: 0%; margin-right: 0%;"><img src="./images/recentPhDGrad.jpg" style="width: 100%; height: auto;" alt=""></div>
<ol id="p-41" class="decimal">
<li id="li-105">
<a class="external" href="https://www.linkedin.com/in/yip-jia-qi/" target="_blank"><code class="code-inline tex2jax_ignore">Yip Jia Qi</code></a>, From Time-domain to Generative Speech Separation (reg Aug 2021, Alibaba scholar PhD) <a class="external" href="https://www.dropbox.com/scl/fi/40c7mlxcfz8qblo081xs0/2025_YipJiaQi_final.pdf?rlkey=458iqptqohyano3rpomfm1f6p?st=6kr67ham?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">(Thesis (final): June 2025) </code></a>
</li>
<li id="li-106">
<a class="external" href="https://sites.google.com/view/hqzou/" target="_blank"><code class="code-inline tex2jax_ignore">Zou HeQing</code></a>, Multimodal Machine Learning (reg Jan 2021, submitted June 2025, PhD) (Sup:Deepu Rajan, Co-Sup: Chng Eng Siong)</li>
<li id="li-107">
<a class="external" href="https://www.linkedin.com/in/chen-chen-4bb7231b8/" target="_blank"><code class="code-inline tex2jax_ignore">Chen Chen</code></a>, Advancing Speech-to-Text Adaptation for Large Speech Models (PhD reg Jan 2021) (defended: June2025) <a class="external" href="https://scholar.google.com.hk/citations?user=uUmSp1QAAAAJ?hl=zh-CN" target="_blank"><code class="code-inline tex2jax_ignore">Google Scholar</code></a>, <a class="external" href="https://www.dropbox.com/scl/fi/v79bwgr475qbdhc4ddtb9/2025_ChenChen_final.pdf?rlkey=907s46bm6avomfaxi7paedsn1?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">(Thesis final: June 2025)</code></a>
</li>
<li id="li-108">
<a class="external" href="https://www.linkedin.com/in/dianwen-ng-34691a129/" target="_blank"><code class="code-inline tex2jax_ignore">Ng Dian Wen</code></a>, Optimizing Speech Representation Learning for Enhanced Noise Robustness in Downstream Applications (PhD reg Jan 2021, graduated 2025 May, Alibaba scholar PhD) <a class="external" href="https://www.dropbox.com/scl/fi/5aped99ygawmsqxy7yr0l/2025_dianwen_final.pdf?rlkey=k6vr2hrzjh974d1tt49th8hld?st=wgmg7bdu?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">(Thesis :May 2025)</code></a>
</li>
<li id="li-109">
<a class="external" href="https://www.linkedin.com/in/rae-jia-xin-koh-9b10b3105/" target="_blank"><code class="code-inline tex2jax_ignore">Rae Koh Jia Xin</code></a>, Singapore English (reg Aug 2019, PhD) (graduated 2025) (Sup: Tan Ying Ying (HSS), Co-Sup: Chng Eng Siong)</li>
<li id="li-110">
<a class="external" href="https://www.linkedin.com/in/andrew-koh-5464a5118/" target="_blank"><code class="code-inline tex2jax_ignore">Andrew Koh Jin Jie</code></a>, Sequence to Sequence Machine Learning (reg Aug 2019, PhD, graduated 2023)</li>
<li id="li-111">
<a class="external" href="https://www.linkedin.com/in/yingzhuzhaophd/" target="_blank"><code class="code-inline tex2jax_ignore">Zhao Yingzhu</code></a>, End-to-End speech recognition (reg Jan 2019, PhD, graduated May 2023). <a class="external" href="https://youtu.be/6vCzAem8Hbo" target="_blank"><code class="code-inline tex2jax_ignore">Oral Defence rehearsal</code></a> <a class="external" href="https://www.dropbox.com/s/x9hcwk383htwlvl/Yingzhu_oral_SlidesApr2023.pptx?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">PhD Slides</code></a> <a class="external" href="https://www.dropbox.com/s/1yf2ajg86777bzq/2023_April_thesis_ZhaoYingzhu.pdf?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">PhD report</code></a> <a class="external" href="https://www.dropbox.com/s/26as7mwlafg0akg/ZhaoYingZhu_PhDThesis_Apr2023Latex.zip?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">PhD latex folder</code></a>
</li>
<li id="li-112">
<a class="external" href="https://www.linkedin.com/in/nana-hou-592a80127/" target="_blank"><code class="code-inline tex2jax_ignore">Hou Nana</code></a>, Robust LVCSR for air traffic control speech (reg Jan 2017, PhD, submitted Jan 2022)</li>
<li id="li-113">
<a class="external" href="https://www.linkedin.com/in/xuchenglin28" target="_blank"><code class="code-inline tex2jax_ignore">Xu Chenglin</code></a>, <a class="external" href="https://www.dropbox.com/s/as78r4txv0z27kc/ChenglinPhDDefenceSlidesAug2020.pptx?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">PhD Slides</code></a> <a class="external" href="https://www.dropbox.com/s/zn6ad5j3lose4r6/ChenglinPhDThesis18July2020.pdf?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">PhD Thesis</code> (2020) Single Channel Multi-talker Speech Separation with Deep Learning</a>
</li>
<li id="li-114">
<a class="external" href="https://www.linkedin.com/in/paul-yaozhu-chan-9408777a/" target="_blank"><code class="code-inline tex2jax_ignore">Paul Chan</code></a>, Synthesis of the human singing voice (2020)</li>
<li id="li-115">
<a class="external" href="https://www.linkedin.com/in/khassanov/" target="_blank"><code class="code-inline tex2jax_ignore">Khassan Yerbolat</code></a>, <a class="external" href="https://www.dropbox.com/s/1z4d6y2fd5crdwk/2020_Khassan_Slides.pptx?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">PhD Slides</code></a>, <a class="external" href="https://www.youtube.com/watch?v=1Dm16krGgv0" target="_blank"><code class="code-inline tex2jax_ignore">Online Presentation</code></a>(April 2020) and final <a class="external" href="https://www.dropbox.com/s/nc6hijq2l6q18ip/Khassan_FinalAmended_Thesis_May2020.pdf?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">PhD thesis.</code></a>, (2020) Language Model Domain Adaptation for Automatic Speech Recognition Systems.</li>
<li id="li-116">
<a class="external" href="https://www.linkedin.com/in/tungpv85/" target="_blank"><code class="code-inline tex2jax_ignore">Pham Van Tung</code></a>, <a class="external" href="https://www.dropbox.com/s/76wrdu426xr4x3z/2019_PhamVanTung_Thesis_amended.pdf?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">PhD Thesis</code></a>(2019) Robust Spoken Term Detection using partial search and re-scoring hypothesized detections techniques. Now in NTU.</li>
<li id="li-117">
<a class="external" href="https://www.linkedin.com/in/xhtian/" target="_blank"><code class="code-inline tex2jax_ignore">Tian Xiaohai</code></a>, <a class="external" href="https://www.dropbox.com/s/pli1uh2i9dr3n0r/2019_Xiaohai_Tian_revised.pdf?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">PhD Thesis</code></a>(2019) Voice Conversion with Parallel/Non-Parallel Data and Synthetic Speech Detection. Now in NUS.</li>
<li id="li-118">
<a class="external" href="https://www.linkedin.com/in/tze-yuang-chong-4b9b2a61/" target="_blank"><code class="code-inline tex2jax_ignore">Chong Tze Yuang</code></a>, <a class="external" href="https://www.dropbox.com/s/9ur3bon1whthsk8/2018_June_ChongTzeYuangPhDThesis.pdf?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">PhD Thesis</code></a>, <a class="external" href="https://www.dropbox.com/s/m8y59n6nv0kqjdu/2018_June_ChongTzeYuang_Presentation.pptx?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">Slides</code></a>, <a class="external" href="https://www.dropbox.com/s/kjfap8a4e1zfnkr/2018_June_ChongTzeYuangPhDThesis_organization.docx?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">Thesis organization</code></a>, (2018) Exploiting Long Context Using Joint  Distance and Occurrence Informationfor Language Modeling.</li>
<li id="li-119">
<a class="external" href="https://www.linkedin.com/in/ha-nguyen-4101517a/" target="_blank"><code class="code-inline tex2jax_ignore">Nguyen Duc Hoang Ha</code></a>, <a class="external" href="https://www.dropbox.com/s/a0gvjb73rqrmb1f/2017_NguyenDucHoangHa_PhDThesis.pdf?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">PhD Thesis</code></a>(2017) <a class="external" href="https://www.dropbox.com/s/pmsluvihe41lk3d/2017_NguyenDucHoangHa_PresentSlide.pdf?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">Slides</code></a> Feature based robust techniques for speech recognition.</li>
<li id="li-120">
<a class="external" href="https://www.linkedin.com/in/trung-hieu-nguyen-a99569b8/" target="_blank"><code class="code-inline tex2jax_ignore">Nguyen Trung Hieu</code></a>, <a class="external" href="https://www.dropbox.com/s/siggnj3dvmu3xq0/2014_NguyenTrungHieu_PhDThesis.pdf?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">PhD Thesis</code></a>(2015). Speaker Diarization in Meeting room domain. Now at Alibaba.</li>
<li id="li-121">
<a class="external" href="https://www.linkedin.com/in/van-hai-do-7a252850/" target="_blank"><code class="code-inline tex2jax_ignore">Do Van Hai</code></a>, <a class="external" href="https://www.dropbox.com/s/0v9npacoacghqwf/2015_DoVanHai_PhDThesis.pdf?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">PhD Thesis</code></a>(2015). Acoustic modelling of speech under limited training data condition. Now in Vietnam Telecoms.</li>
<li id="li-122">
<a class="external" href="https://www.linkedin.com/in/zhizhengwu/" target="_blank"><code class="code-inline tex2jax_ignore">Wu Zhizheng</code></a>, <a class="external" href="https://www.dropbox.com/s/m6u9ccmuvkbo0av/2015_WuZZ_PhDThesis.pdf?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">PhD Thesis</code></a>(2015). Spectral Mapping for Voice Conversion.</li>
<li id="li-123">
<a class="external" href="https://www.linkedin.com/in/jonathan-dennis-9ab85186/" target="_blank"><code class="code-inline tex2jax_ignore">Jonathan Dennis</code></a>, <a class="external" href="https://www.dropbox.com/s/zpxrbvlhto7199y/2014_JohnDennis_PhDThesis2014.pdf?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">PhD Thesis</code></a>(2014). <a class="external" href="https://www.dropbox.com/s/72md2vuw2jebjmy/2014_JonDennis_PhD_oral_defence_slides.pptx?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">Slides</code></a>,  Sound Event Recognition in Unstructured Environments using Spectrogram Image Processing.</li>
<li id="li-124">
<a class="external" href="https://www.linkedin.com/in/lei-wang-44190967/" target="_blank"><code class="code-inline tex2jax_ignore">Wang Lei</code></a>, (2013). Audio Pattern Discovery and retrieval.</li>
<li id="li-125">
<a class="external" href="https://www.linkedin.com/in/rong-tong-3028924a/" target="_blank"><code class="code-inline tex2jax_ignore">Tong Rong</code></a>, <a class="external" href="https://www.dropbox.com/s/gcqmbqaq9vd52si/2012_TongRong_PhDThesis.pdf?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">PhD Thesis</code></a>(2012). Towards high performance phonotactic features for spoken language recognition. Now at Alibaba.</li>
<li id="li-126">
<a class="external" href="https://www.linkedin.com/in/omiddehzangi/" target="_blank"><code class="code-inline tex2jax_ignore">Omid Dehzanghi</code></a>, (2012). Discriminative Learning for speech recognition, U of Michigan</li>
<li id="li-127">
<a class="external" href="https://www.linkedin.com/in/xiong-xiao-0a6a9b29/" target="_blank"><code class="code-inline tex2jax_ignore">Xiao Xiong</code></a>, <a class="external" href="https://www.dropbox.com/s/ywqbhkz0vfnh06s/2009_XiaoXiong_PhDThesis.pdf?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">PhD Thesis (2009)</code></a>. PhD Thesis: Robust speech features and acoustic models for speech recognition. <a class="external" href="https://www.dropbox.com/s/7muljjnvlqn5f7r/2006_XiaoXiong_PhD_QE.pdf?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">QE (2006)</code></a>,Speech Enhancement with Applications in speech recognition,  now in Microsoft, US  since Apr 2017</li>
<li id="countGraduatedPhD">
<a class="external" href="https://www.linkedin.com/in/wangjinjun/" target="_blank"><code class="code-inline tex2jax_ignore">Wang Jinjun</code></a>, PhD (2008), Content based sports video analysis and composition. Now in Xian Jiaotong.</li>
</ol></section><section class="subsection" id="Past_MEng_Students"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">2.4.5</span> <span class="title">Past MEng Students</span>
</h3>
<a href="my_Students.html#Past_MEng_Students" class="permalink">¶</a><ol id="p-42" class="decimal">
<li id="li-129">
<a class="external" href="https://www.linkedin.com/in/adnan-azmat-496000153/?originalSubdomain=sg" target="_blank"><code class="code-inline tex2jax_ignore">Azmat Adnan</code></a>,(MSAI Thesis, 2024) Robust Diarization</li>
<li id="li-130">
<a class="external" href="https://www.linkedin.com/in/tanmay-surana-118a79192/" target="_blank"><code class="code-inline tex2jax_ignore">Tanmay Surana</code></a>, <code class="code-inline tex2jax_ignore">Deep Learning-based Text Augmentation for Named Entity Recognition</code> (reg Aug 2021, MEng, completed Oct 2023)</li>
<li id="li-131">
<a class="external" href="https://www.linkedin.com/in/chaiyasait/" target="_blank"><code class="code-inline tex2jax_ignore">Prachaseree Chaiyasait</code></a>, Adaptation of Language Models via Text Augmentation (reg Aug 2021, MEng, submitted Jul 2023, completed Oct 2023)</li>
<li id="li-132">
<a class="external" href="https://www.linkedin.com/in/kyaw-zin-tun-170b52122" target="_blank"><code class="code-inline tex2jax_ignore">Kyaw Zin Tun</code></a>, Name entity recognition for chatbot applcications(MEng, started Aug 2020, submitted thesis Aug 2022)</li>
<li id="li-133">
<a class="external" href="https://www.linkedin.com/in/fuzhao-xue-6410561a6/" target="_blank"><code class="code-inline tex2jax_ignore">Xue Fuzhao</code></a>, Information extraction from text (MEng 2020)</li>
<li id="li-134">
<a class="external" href="https://sg.linkedin.com/in/lim-zhi-hao-025546115" target="_blank"><code class="code-inline tex2jax_ignore">Lim Zhi Hao</code></a>, (MEng 2020), Anti-Spoofing Techniques for Robust Speaker Verification<a class="external" href="https://www.dropbox.com/s/tjhprq3dvj79hjm/2020_LimZhiHao_Robust_Speaker_Verification.pdf?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">Thesis (2020)</code></a>
</li>
<li id="li-135">
<a class="external" href="https://www.linkedin.com/in/ngaho/" target="_blank"><code class="code-inline tex2jax_ignore">Ho Thi Nga</code></a>, (MEng 2019), Sentence unit detection for automatic speech transcripts using lexical information</li>
<li id="li-136">
<a class="external" href="https://www.linkedin.com/in/su-jun-leow-52755085/" target="_blank"><code class="code-inline tex2jax_ignore">Leow Sujun</code></a>, (MEng 2018), Image Processing Technique for Speech Signal Processing</li>
<li id="li-137">
<a class="external" href="https://www.linkedin.com/in/hy-nguyen-quy-61292739/" target="_blank"><code class="code-inline tex2jax_ignore">Nguyen Quy Hy</code></a>, (MEng 2017), Voice conversion using DNN</li>
<li id="li-138">
<a class="external" href="https://www.linkedin.com/in/steven-du-1662511b/" target="_blank"><code class="code-inline tex2jax_ignore">Steven Du</code></a>, (MEng 2015),  Robust Front End for Speaker Verification</li>
<li id="li-139">
<a class="external" href="https://www.linkedin.com/in/terence-ng-70411320/" target="_blank"><code class="code-inline tex2jax_ignore">Terrence Ng Wen Zheng</code></a>, <a class="external" href="https://www.dropbox.com/s/2staf3jboruaozr/2014_MENG_TerrenceNgWenZheng.pdf?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">Thesis</code></a>,(MEng 2014), Sound Event recognition in home environment</li>
<li id="li-140">
<a class="external" href="https://www.linkedin.com/in/wenda-chen-6261732a/" target="_blank"><code class="code-inline tex2jax_ignore">Chen Wenda</code></a>, (MEng 2014),Computer Assisted Language Learning</li>
<li id="li-141">
<a class="external" href="https://www.linkedin.com/in/pckben/" target="_blank"><code class="code-inline tex2jax_ignore">Ben Pham Chau Khoa</code></a>, <a class="external" href="https://www.dropbox.com/s/tfvf6sx3wpb9eeb/2012_MEng_BenPhamChauKhoa.pdf?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">Thesis</code></a>,(MEng 2012), Robust VAD</li>
<li id="countGraduatedMEng">Eugene Koh, (MEng 2009), Speaker Diarizaton</li>
</ol></section><section class="subsection" id="Past_MSAI_Students"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">2.4.6</span> <span class="title">Past MSAI Students and Other collaboration students</span>
</h3>
<a href="my_Students.html#Past_MSAI_Students" class="permalink">¶</a><ol id="p-43" class="decimal">
<li id="li-143">
<a class="external" href="https://www.linkedin.com/in/yanru-chen-2b38b8221/" target="_blank"><code class="code-inline tex2jax_ignore">Chen Yanru</code></a> (2024 Jan~), Masters Data Science, Classification of Depression Syndrome by Deep Learning</li>
<li id="li-144">
<a class="external" href="https://www.linkedin.com/in/xiaokaiqin/" target="_blank"><code class="code-inline tex2jax_ignore">Qin Xiaokai</code></a> (2023 Aug~), MSAI student, Deepfake audio generation using voice conversion</li>
<li id="li-145">
<a class="external" href="https://in.linkedin.com/in/adnan-azmat-496000153" target="_blank"><code class="code-inline tex2jax_ignore">Azmat Adnan</code></a> (Reg 2023 Aug, completed Aug 2024), MSAI student, DNN Approaches for noisy speech diarization</li>
<li id="li-146">
<code class="code-inline tex2jax_ignore">Zhuo Ning</code> (Reg 2023 Aug, completed Aug 2024), Masters Cybersecurity student, Deep Fake Corpus developmenet and detection</li>
<li id="li-147">
<code class="code-inline tex2jax_ignore">Jiang Yufei</code> (2022 Aug~ 2023 Aug), MSAI (NTU), Adopting Neural Translation Model in Data Generation for Inverse Text Normalization</li>
<li id="li-148">
<code class="code-inline tex2jax_ignore">Liu Jiaxing</code> (2021 Oct ~2023 Oct, CSC visitor, PhD student Tianjin University, China), Multi-modal emotion recognition</li>
<li id="li-149">
<code class="code-inline tex2jax_ignore">Cheng Qi</code> (2021 Oct ~2022 Oct, CSC visitor, PhD student Harbin Engineering Uni, China), Graph Neural Network for Lattice rescoring</li>
<li id="li-150">
<a class="external" href="https://www.linkedin.com/in/samuel-samsudin-ng/" target="_blank"><code class="code-inline tex2jax_ignore">Samuel Samsudin Ng</code></a>, (MSAI 2020-S1), Speech emotion recognition with AlexNet and Fully convolutional network, <a class="external" href="https://www.dropbox.com/s/3ullgc88cfihj2e/2020_MSAI_Report_SamuelSamsudinNg.pdf?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">Sam's MSAI Thesis</code></a>, <a class="external" href="https://github.com/samsudinng/speech_emo_recognition.git" target="_blank"><code class="code-inline tex2jax_ignore">github depository</code></a>, <a class="external" href="https://www.kaggle.com/samuelsamsudinng/iemocap-emotion-speech-database" target="_blank"><code class="code-inline tex2jax_ignore">kaggle iEmoCap</code></a>
</li>
<li id="li-151">
<a class="external" href="https://www.linkedin.com/in/andy-cheung-a0847572/" target="_blank"><code class="code-inline tex2jax_ignore">Cheung Chin Ka</code></a>, (MSAI 2020-S1), Acoustic Scene Classication with cutting edge hyperparameter tuning tool, <a class="external" href="https://www.dropbox.com/s/0bpudw98ra4f80k/2020_msai-cheung-chin-ka-master-project-report.pdf?dl=0" target="_blank"><code class="code-inline tex2jax_ignore">Andy's MSAI Thesis</code></a>
</li>
<li id="li-152">
<a class="external" href="https://www.linkedin.com/in/bozhong-sampson-liu/" target="_blank"><code class="code-inline tex2jax_ignore">Liu Bozhong</code></a>, (MSAI 2020-S2), Wakeup keyword detection for far-field microphone array using end to end framework</li>
</ol></section><section class="subsection" id="PastStudents"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">2.4.7</span> <span class="title">Past MSAI Students and Other collaboration students</span>
</h3>
<a href="my_Students.html#PastStudents" class="permalink">¶</a><ol id="p-44" class="decimal">
<li id="li-153">
<code class="code-inline tex2jax_ignore">Zhao Yang</code> (2021 Oct ~2023 Oct, CSC visitor, PhD student Xian JiaoTong Uni, China), Semi/Self supervised representation for speech recognition</li>
<li id="li-154">
<code class="code-inline tex2jax_ignore">Peng Yizhou</code> (2020 June ~2022 June, Masters student Xinjiang, China), ASR development (Kaldi and End2End)</li>
<li id="li-155">
<code class="code-inline tex2jax_ignore">Yang Yuhang</code> (2021 June~2023 June, Masters student Xinjiang, China), WeNet ASR, End2End ASR</li>
<li id="li-156">
<code class="code-inline tex2jax_ignore">Guo Yachao</code> (2021 June~2023 June, Masters student Xinjiang, China), End2End Hotword LM Adaptation</li>
</ol></section></section></div></main>
</div>
</body>
</html>
