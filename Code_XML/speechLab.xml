<?xml version="1.0" encoding="UTF-8"?>
<chapter xml:id="SpeechLab">
    <title>Speech and Language Laboratory</title>

    <section xml:id="speechLab_intro">
        <title>Speech and Language laboratory</title>

        <introduction>
            <p>The speech and language research group in SCSE was founded in 2007 by Chng Eng Siong and
            <url href="http://www.colips.org/~eleliha/"><c>Prof Li Haizhou</c></url> (now in NUS, Singapore). 
            The group is now situated within <url href="https://maps.ntu.edu.sg/maps#q:MICL"><c>Media and Interactive Computing Lab</c></url> in SCSE. We also founded the <url href="https://makerspace.aisingapore.org/do-ai/speech-lab/"><c>AISG Speech Lab</c></url> funded by NRF in 2018.
            </p>
        </introduction>

        <subsection>
            <title>Research Focus</title>
            <p> Our research interest is primarily speech and language processing, classifications using ML:</p>
            <ol label="a">     
                <li>Code-switch speech recognition</li>
                <li>Robust Large vocabulary continuous speech recognition and Keyword spotting</li>
                <li>Speech enhancement: speaker extraction, denoising, feature enhancement, overlapping speech extraction</li>
                <li>Speaker identification and speaker diarization</li>
                <li>Towards Speech Understanding (ChatBot) - some aspects of NLP such as topic detection, name entity recognition</li>
                <li>Audio event and scene classifications</li>
            </ol>


	<p>	Examples of relevant papers to the research area include:
	<url href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46687.pdf"><c>sequence to sequence model</c></url>
	which has been widely studied in <url href="https://arxiv.org/abs/1609.08144"><c>machine translation</c></url>. 
	The problems we are keen on include
	<ul>
		<li>	Code switch end to end and Adaptation -> 
			how to improve the model in certain target environment (speaker, noise, type of dialogues), etc.
		<url href="https://dblp.org/pers/p/Pham:Van_Tung.html"><c>Code-switch End-to-end</c></url></li>

		<li>	Classification-> what type of sound is this? <url href="http://dcase.community/challenge2019/index"><c>Audio Scene and Event Analysis</c></url></li>
		<li>    Speaker id: who spoke it: <url href="http://danielpovey.com/files/2019_interspeech_xvector_refinement.pdf"><c>speaker id</c></url>
				under <url href="https://arxiv.org/pdf/1902.02546.pdf"><c>overlapping condition</c></url> 
				and  <url href="https://ai.googleblog.com/2018/11/accurate-online-speaker-diarization.html"><c>when (Diarization).</c></url></li>

		<li> 	Speech Enhancement -  <url href="https://www.researchgate.net/publication/340643534_SpEx_Multi-Scale_Time_Domain_Speaker_Extraction_Network"><c>speaker extraction</c></url> and 
				<url href="https://link.springer.com/article/10.1186/s13634-015-0300-4"><c>derevberation</c></url>.</li>

	</ul>
	</p>


        </subsection>            

        <subsection>
            <title>Demos</title>
            <p>Some of our previous works:</p>
            <ol label='1'>
               <li> <p>Youtube recordings: Our code-switch speech recognition in action:
                    <ol label="a">
                    <li><url href="https://www.youtube.com/watch?v=qfLTJkvYZYc"><c>Recognizing  English/Mandarin code-switch speech using our LVCSR system</c></url> (2018 June).</li>
                    <li><url href="https://www.youtube.com/watch?v=wuQQ3fLu5yE"><c>Comparing our system against  Google, Siri</c></url> (2018 Sep).</li>
                    </ol>
                </p></li>

                <li><p>Source separation - Separating Hillary Clinton and Trump voice from Youtube recording, from Chenglin's  
                    <url href="https://www.dropbox.com/s/jdzrwz1ojobad35/2018_Chenglin_DemoTrumpvsHillary.pptx?dl=0"><c>Demo slide</c></url> (Oct 2018)</p></li>

            
                <li><p>Speech indexing using our MAGOR system (Code-switch English/Mandarin and Malay system)
                <image source = './images/magor_picture.jpg' /></p> </li>


            </ol>
        </subsection>            

        <subsection>
            <title>Our recent demos using our speech engine</title>
            <p>2020 FYPs demo:</p>
            <ol label='1'>

                <li><p>Deploying Speech Recognition System using high availability and scalability kubernetes cluster <url href="https://www.youtube.com/watch?v=le79VEOjeuQ"><c>Youtube</c></url></p></li>

                 <li><p>Chatbot framework using Dialog flow and various Q and A modules (2020 Demo)
                    <url href="https://www.youtube.com/watch?v=upFpCp4LDgo"><c>Youtube</c></url>
                    and a live demo<url href="https://chatbot.speechlab.sg/"><c>Demo</c></url>
                    <image source = './images/russell_chatbotPic2020.jpg' /> </p> </li>

            </ol>
        </subsection>            
    </section>
            

    <section xml:id="my_collaborator">
           <title>Collaborators</title>
            <p><ol label="1">
            <li><url href="http://ece.nus.edu.sg/hlt/"><c>Prof Li Haizhou</c></url>, NUS, Singapore and AISG Speech Lab.</li>
            <li><url href="http://csee.hnu.edu.cn/people/zhongxionghu"><c>Prof Zhong Xionghu</c></url>, Hunan University, China. Microphone Array DOA and diarization.</li>
            <li><url href="https://www.linkedin.com/in/bin-ma-b278a44b/"><c>Dr Ma Bin</c></url>, Alibaba. Robust End-to-End Code switch ASR.</li>
            <li><url href="https://www.xju-aslp.cn/"><c>Prof Huang Hao</c></url>, Xinjiang University. PhD students exchange -  Code switch ASR and classification.</li>
            <li><url href="http://www.nwpu-aslp.org/lxie/"><c>Prof Xie Lei</c></url>, Northwestern Polytechnic, Xian, China. PhD students exchange - ASR.</li>
            <li><url href="http://cic.tju.edu.cn/faculty/wanglongbiao/experiences.html"><c>Prof Wang Longbiao</c></url>, Tianjin University, China. PhD students exchange - Emotion recognition</li>
            <li><url href="https://www.linkedin.com/in/rafaelbanchs/"><c>Dr Raphael Banchs</c></url>, ChatBot.</li>
            </ol></p>

    <subsection xml:id="Past_collaborator">
           <title>Past Collaborators</title>
            <p><ol label="1">
            <li><url href="https://chl.ece.gatech.edu/"><c>Prof Lee Chin Hui</c></url>, Robust ASR (~2008-2015) </li>
            <li><url href="https://www.uni-bremen.de/en/csl/team/staff/prof-dr-ing-tanja-schultz/"><c>Prof Tanja Schultz</c> (~2008-2013)</url>, Code-switch ASR</li>
            </ol></p>
    </subsection>


    </section>

    <section xml:id="my_Staff">
            <title>Staff</title>
            <p><ol label="1">
            <li><url href="https://www.linkedin.com/in/haihua-xu-42757419"><c>Dr Xu Haihua</c></url>, Senior Research Fellow, Robust LVCSR, keyword spotting</li>
            <li><url href="https://www.linkedin.com/in/tungpv85/"><c>Dr Pham Van Tung</c></url>, Research Fellow, Speech recognition, end-to-end, keyword spotting</li>
            <li><url href="https://www.linkedin.com/in/RajendraPrasadSirigina9b691859/"><c>Dr Rajendra Prasad Sirigina</c></url>, Research Fellow, Time series </li>
            <li><url href="https://sg.linkedin.com/in/ngaho"><c>Ho Thi Nga></c></url>, sentence unit detection and full-stack, backend.</li>
            <li><url href="https://sg.linkedin.com/in/lim-zhi-hao-025546115"><c>Lim Zhi Hao</c></url> Speaker verification</li>
            <li><url href="https://www.linkedin.com/in/lyvt1/"><c>Ly Vu Thi</c></url>,Full-stack and chatBot</li>
            <li><url href="https://www.linkedin.com/in/kyaw-zin-tun-170b52122"><c>Kyaw Zin Tun</c></url>, full-stack development</li>
            <li><url href="https://www.linkedin.com/in/duc-mai-trung-1410/"><c>Mai Trung Duc</c></url>, full-stack and mobile app development   </li>
            <li><url href="https://www.linkedin.com/in/maduo-843771197/"><c>Ma Duo</c></url>, LVCSR and classification</li>
            <li><url href="https://www.linkedin.com/in/nabilah-ismail-6b3aa0164"><c>Nabilah Ismail</c></url>, Corpus Development</li>

            </ol></p>

    <subsection xml:id="Past_Staff">
    <title>Past Staff</title>
    <p><ol label="1">
            <li><url href="https://www.linkedin.com/in/xuchenglin28"><c>Xu Chenglin</c></url>, PhD (2020), 
            Single Channel Multi-talker Speech Separation with Deep Learning</li>
            <li><url href="https://www.linkedin.com/in/zengzhiping/"><c>Zeng Zhiping</c></url>, LVCSR, March 2018- April 2020</li>
            <li><url href="https://www.linkedin.com/in/danyuan-ho-4a7312173/"><c>Ho Danyuan</c></url>, corpus development and linguistic, May 2018-March 2020</li>
            <li><url href="https://www.linkedin.com/in/xhtian/"><c>Tian XiaoHai</c></url>, TTS and voice morphing, part-time PhD and Staff, 2013-2018. Now in NUS.</li>
            <li><url href="https://www.linkedin.com/in/wei-rao-49382080"><c>Rao Wei</c></url>, Speaker verification, 2015-2018, Now in NUS.</li>
            <li><url href="https://www.linkedin.com/in/xiong-xiao-0a6a9b29/"><c>XiaoXiong</c></url>, PhD Student 2004-2008, Staff 2008-2017, Now in Microsoft, Redmond - since Apr 2017</li>
            <li><url href="https://www.linkedin.com/in/benjamin-bigot-ab175291/"><c>Benjamin Bigot</c></url>, 2014-2016 - LVCSR for RR</li>
            <li><url href="https://orcid.org/0000-0001-5880-7956"><c>Huang Guangpu</c></url>, 2012-2015 - Articulatory Phonetics Features  </li>
            <li><url href="https://www.linkedin.com/in/dau-cheng-lyu-48794916/"><c>Lyu Daucheng</c></url>,  2009-2013 - Code switch LVCSR</li>
            <li><url href="https://www.linkedin.com/in/shengkui-zhao-%EF%BC%88%E8%B5%B5%E8%83%9C%E5%A5%8E%EF%BC%89-74983b22/"><c>Zhao Shengkui</c></url>,2009-2010 - Microphone array and beamforming.</li>

        </ol></p>
    </subsection>


    </section>




    <section xml:id="my_Students">
            <title>Graduate Students</title>
            <p><ol label="1">
            <li><url href="https://www.linkedin.com/in/andrew-koh-5464a5118/"><c>Andrew Koh Jin Jie</c></url>, question and answer for chatbot (reg Aug 2019, PhD)</li>
            <li><url href="https://www.linkedin.com/in/alanwuha/"><c>Alan Tan Lai Chian></c></url>,Monitoring Air Traffic Control Dialogue (reg Aug 2019, PhD)</li>
            <li><url href="https://www.linkedin.com/in/rae-jia-xin-koh-9b10b3105/"><c>Rae Koh Jia Xin</c></url>, Singapore English (reg Aug 2019, PhD)</li>
            <li><url href="https://www.linkedin.com/in/yingzhuzhaophd/"><c>Zhao Yingzhu></c></url>, End-to-End speech recognition (reg Jan 2019, PhD)</li>
            <li><url href="https://www.linkedin.com/in/nana-hou-592a80127/"><c>Hou Nana></c></url>, Robust LVCSR for air traffic control speech (reg Jan 2017, PhD)</li>
            <li><url href="https://www.linkedin.com/in/zhongwei-li-1b22075/"><c>Li Zhongwei</c></url>, Name and Digit Entity Recognition for simultaneous translation (partTime PhD, reg 2016)</li>
            <li><url href="https://www.linkedin.com/in/fuzhao-xue-6410561a6/?originalSubdomain=cn"><c>Xue Fuzhao</c></url>, Information extraction from text (MEng, reg 2020)</li>
            </ol></p>

    <subsection xml:id="Past_PhD_Students">
    <title>Past PhD Students</title>
    <image source = './images/recentPhDGrad.jpg' /> 
    <p><ol label="1" >

	    <li><url href="https://www.linkedin.com/in/xuchenglin28"><c>Xu Chenglin</c></url>,
 	    <url href="https://www.dropbox.com/s/as78r4txv0z27kc/ChenglinPhDDefenceSlidesAug2020.pptx?dl=0"><c>PhD Slides</c></url>
		<url href="https://www.dropbox.com/s/zn6ad5j3lose4r6/ChenglinPhDThesis18July2020.pdf?dl=0"><c>PhD Thesis</c> (2020) Single Channel Multi-talker Speech Separation with Deep Learning</url></li>

 	    <li><url href="https://www.linkedin.com/in/paul-yaozhu-chan-9408777a/"><c>Paul Chan</c></url>, Synthesis of the human singing voice (2020)</li>

        <li><url href="https://www.linkedin.com/in/khassanov/"><c>Khassan Yerbolat</c></url>, <url href=
        "https://www.dropbox.com/s/1z4d6y2fd5crdwk/2020_Khassan_Slides.pptx?dl=0"><c>PhD Slides</c> </url>,
        <url href="https://www.youtube.com/watch?v=1Dm16krGgv0"><c>Online Presentation</c></url>(April 2020)
        and final <url href="https://www.dropbox.com/s/nc6hijq2l6q18ip/Khassan_FinalAmended_Thesis_May2020.pdf?dl=0"><c>PhD thesis.</c></url>,
        (2020) Language Model Domain Adaptation for Automatic Speech Recognition Systems.</li>


        <li><url href="https://www.linkedin.com/in/tungpv85/"><c>Pham Van Tung</c></url>, <url href="https://www.dropbox.com/s/76wrdu426xr4x3z/2019_PhamVanTung_Thesis_amended.pdf?dl=0"><c>PhD Thesis</c> </url>(2019) Robust Spoken Term Detection using partial search and re-scoring hypothesized detections techniques. Now in NTU.</li>

        <li><url href="https://www.linkedin.com/in/xhtian/"><c>Tian Xiaohai</c></url>, <url href="https://www.dropbox.com/s/pli1uh2i9dr3n0r/2019_Xiaohai_Tian_revised.pdf?dl=0"><c>PhD Thesis</c> </url>(2019) Voice Conversion with Parallel/Non-Parallel Data and Synthetic Speech Detection. Now in NUS.</li>
        
        <li><url href="https://www.linkedin.com/in/tze-yuang-chong-4b9b2a61/"><c>Chong Tze Yuang</c></url>, <url href="https://www.dropbox.com/s/9ur3bon1whthsk8/2018_June_ChongTzeYuangPhDThesis.pdf?dl=0"><c>PhD Thesis</c></url>, <url href="https://www.dropbox.com/s/m8y59n6nv0kqjdu/2018_June_ChongTzeYuang_Presentation.pptx?dl=0"><c>Slides</c></url>,
        <url href="https://www.dropbox.com/s/kjfap8a4e1zfnkr/2018_June_ChongTzeYuangPhDThesis_organization.docx?dl=0"><c>Thesis organization</c></url>,
        (2018) Exploiting Long Context Using Joint  Distance and Occurrence Informationfor Language Modeling.</li>

        <li><url href="https://www.linkedin.com/in/ha-nguyen-4101517a/"><c>Nguyen Duc Hoang Ha</c></url>, <url href="https://www.dropbox.com/s/a0gvjb73rqrmb1f/2017_NguyenDucHoangHa_PhDThesis.pdf?dl=0"><c>PhD Thesis</c> </url>(2017) <url href="https://www.dropbox.com/s/pmsluvihe41lk3d/2017_NguyenDucHoangHa_PresentSlide.pdf?dl=0"><c>Slides</c></url>
        Feature based robust techniques for speech recognition.</li>

        <li><url href="https://www.linkedin.com/in/trung-hieu-nguyen-a99569b8/"><c>Nguyen Trung Hieu</c></url>, <url href="https://www.dropbox.com/s/siggnj3dvmu3xq0/2014_NguyenTrungHieu_PhDThesis.pdf?dl=0"><c>PhD Thesis</c> </url>(2015). Speaker Diarization in Meeting room domain. Now at Alibaba.</li>

        <li><url href="https://www.linkedin.com/in/van-hai-do-7a252850/"><c>Do Van Hai</c></url>, <url href="https://www.dropbox.com/s/0v9npacoacghqwf/2015_DoVanHai_PhDThesis.pdf?dl=0"><c>PhD Thesis</c> </url>(2015). Acoustic modelling of speech under limited training data condition. Now in Vietnam Telecoms.</li>

        <li><url href="https://www.linkedin.com/in/zhizhengwu/"><c>Wu Zhizheng</c></url>, <url href="https://www.dropbox.com/s/m6u9ccmuvkbo0av/2015_WuZZ_PhDThesis.pdf?dl=0"><c>PhD Thesis</c> </url>(2015). Spectral Mapping for Voice Conversion.</li>

        <li><url href="https://www.linkedin.com/in/jonathan-dennis-9ab85186/"><c>Jonathan Dennis</c></url>, <url href="https://www.dropbox.com/s/zpxrbvlhto7199y/2014_JohnDennis_PhDThesis2014.pdf?dl=0"><c>PhD Thesis</c> 
        </url>(2014). <url href="https://www.dropbox.com/s/72md2vuw2jebjmy/2014_JonDennis_PhD_oral_defence_slides.pptx?dl=0"><c>Slides</c> </url>,  Sound Event Recognition in Unstructured Environments using Spectrogram Image Processing.</li>

        <li><url href="https://www.linkedin.com/in/lei-wang-44190967/"><c>Wang Lei</c></url>, (2013). Audio Pattern Discovery and retrieval.</li>

        <li><url href="https://www.linkedin.com/in/rong-tong-3028924a/"><c>Tong Rong</c></url>, <url href="https://www.dropbox.com/s/gcqmbqaq9vd52si/2012_TongRong_PhDThesis.pdf?dl=0"><c>PhD Thesis</c> </url>(2012). Towards high performance phonotactic features for spoken language recognition. Now at Alibaba.</li>

        <li><url href="https://www.linkedin.com/in/omiddehzangi/"><c>Omid Dehzanghi</c></url>, (2012). Discriminative Learning for speech recognition, U of Michigan</li>

        <li><url href="https://www.linkedin.com/in/xiong-xiao-0a6a9b29/"><c>Xiao Xiong</c></url>, <url href="https://www.dropbox.com/s/ywqbhkz0vfnh06s/2009_XiaoXiong_PhDThesis.pdf?dl=0"><c>PhD Thesis (2009)</c> 
        </url>. PhD Thesis: Robust speech features and acoustic models for speech recognition. <url href="https://www.dropbox.com/s/7muljjnvlqn5f7r/2006_XiaoXiong_PhD_QE.pdf?dl=0"><c>QE (2006)</c> </url>,Speech Enhancement with Applications in speech recognition,  now in Microsoft, US  since Apr 2017</li>

        <li xml:id="countGraduatedPhD"><url href="https://www.linkedin.com/in/wangjinjun/"><c>Wang Jinjun</c></url>, PhD (2008), Content based sports video analysis and composition. Now in Xian Jiaotong. </li>
    </ol></p>
    </subsection>


    <subsection xml:id="Past_MEng_Students">
    <title>Past MEng Students</title>
    <p><ol label="1">
        <li><url href="https://sg.linkedin.com/in/lim-zhi-hao-025546115"><c>Lim Zhi Hao</c></url>, (MEng 2020), Anti-Spoofing Techniques for Robust
        Speaker Verification<url href="https://www.dropbox.com/s/tjhprq3dvj79hjm/2020_LimZhiHao_Robust_Speaker_Verification.pdf?dl=0"><c>Thesis (2020)</c></url></li>
        <li><url href="https://www.linkedin.com/in/ngaho/"><c>Ho Thi Nga</c></url>, (MEng 2019), Sentence unit detection for automatic speech transcripts using lexical information</li>
        <li><url href="https://www.linkedin.com/in/su-jun-leow-52755085/"><c>Leow Sujun</c></url>, (MEng 2018), Image Processing Technique for Speech Signal Processing</li>
        <li><url href="https://www.linkedin.com/in/hy-nguyen-quy-61292739/"><c>Nguyen Quy Hy</c></url>, (MEng 2017), Voice conversion using DNN</li>
        <li><url href="https://www.linkedin.com/in/steven-du-1662511b/"><c>Steven Du</c></url>, (MEng 2015),  Robust Front End for Speaker Verification</li>
        <li><url href="https://www.linkedin.com/in/terence-ng-70411320/"><c>Terrence Ng Wen Zheng</c></url>, 
        <url href="https://www.dropbox.com/s/2staf3jboruaozr/2014_MENG_TerrenceNgWenZheng.pdf?dl=0"><c>Thesis</c></url>,(MEng 2014), Sound Event recognition in home environment</li>
        <li><url href="https://www.linkedin.com/in/wenda-chen-6261732a/"><c>Chen Wenda</c></url>, (MEng 2014),Computer Assisted Language Learning</li>
        <li><url href="https://www.linkedin.com/in/pckben/"><c>Ben Pham Chau Khoa</c></url>, (MEng 2014),Computer Assisted Language Learning
            <url href="https://www.dropbox.com/s/tfvf6sx3wpb9eeb/2012_MEng_BenPhamChauKhoa.pdf?dl=0"><c>Thesis</c></url>,(MEng 2012), Robust VAD</li>
        <li xml:id="countGraduatedMEng"> Eugene Koh, (MEng 2009), Speaker Diarizaton</li>
    </ol></p>
    </subsection>
    </section>




    <section xml:id="Past_Interns">
    <title>Past (mainly undergraduate) Interns</title>
    <introduction>
    The list is incomplete, we began to the tradition of taking pictures with the students from India about 2017,  there were many others. 
    The pictures here mainly are undergraduate students, and details included inside. Students are invited here for six months to work with us. 
    Pls send me an email about 8-9 months before start of internship, typically Jan or June each year for consideration).
    </introduction>
    <p><ol label="1">
            <li><url href="https://www.dropbox.com/s/6jncuc9srnekg3o/MICL_Interns_AugDec2020.pdf?dl=0"><c>Interns from 2020 (July-Dec) </c></url></li>
            <li><url href="https://www.dropbox.com/s/qj1c3lytdy8b7mz/MICL_Interns_feb2020.pdf?dl=0"><c>Interns from 2020 (Jan-May) </c></url></li>
            <li><url href="https://www.dropbox.com/s/eu0ewshlvcpu9xp/MICL_Interns_Nov%202019_Grp1.pdf?dl=0"><c>Interns from 2019 (Nov, Grp1)</c></url></li>
            <li><url href="https://www.dropbox.com/s/cbeqnrd5vu7nl9s/MICL_Interns_Nov%202019_Grp2.pdf?dl=0"><c>Interns from 2019 (Nov, Grp2)</c></url></li>
            <li><url href="https://www.dropbox.com/s/e7t42elpkkepxla/MICL_Interns_July2019.pdf?dl=0"><c>Interns from 2019 (Jul)</c></url></li>
            <li><url href="https://www.dropbox.com/s/hhvxdkrsy36umxp/MICL_interns_Apr2019.pdf?dl=0"><c>Interns from 2019 (Apr)</c></url></li>
            <li><url href="https://www.dropbox.com/s/5kvr37n34m5dgso/InternsGroupPhotoOct2018a.pdf?dl=0"><c>Interns from 2018 (Oct)</c></url></li>
            <li><url href="https://www.dropbox.com/s/p96jev90lw1n5iq/InternsGroupPhotoJuly2018.pdf?dl=0"><c>Interns from 2018 (Jul)</c></url></li>
            <li><url href="https://www.dropbox.com/s/yur445nl12lwvlk/InternsGroupPhotoMay2018.pdf?dl=0"><c>Interns from 2018 (May)</c></url></li>
            <li><url href="https://www.dropbox.com/s/u16qn9f4lu7hqai/InternsGroupPhotoJan2018.pdf?dl=0"><c>Interns from 2018 (Jan)</c></url></li>
            <li><url href="https://www.dropbox.com/s/hup912rma6p9loc/MMLInternsNTU2017.pdf?dl=0"><c>Interns from 2017 (Jul)</c></url></li>
            <li><url href="http://www.linkedin.com/in/gangeshwark"><c>Gangeshwar Krishnamurthy,2017 (Jan-Apr)</c></url></li>
            <li><url href="https://www.linkedin.com/in/shengheng-gao-2779043a/"><c>Gao Shengheng,2016 (Mar-Jun)</c></url></li>
            </ol></p>
    </section>
    
</chapter>
